<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>SML Help</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="A resource for learning SML">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">Welcome!</a></li><li class="chapter-item expanded "><a href="start/index.html"><strong aria-hidden="true">1.</strong> Getting Started</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="start/install.html"><strong aria-hidden="true">1.1.</strong> Install &amp; run SML</a></li><li class="chapter-item expanded "><a href="start/syntax.html"><strong aria-hidden="true">1.2.</strong> Syntax Cheatsheet</a></li><li class="chapter-item expanded "><a href="start/common.html"><strong aria-hidden="true">1.3.</strong> Common Tasks</a></li></ol></li><li class="chapter-item expanded "><a href="types/index.html"><strong aria-hidden="true">2.</strong> Types &amp; Signatures</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="types/type.html"><strong aria-hidden="true">2.1.</strong> Types</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="types/bool.html"><strong aria-hidden="true">2.1.1.</strong> bool</a></li><li class="chapter-item expanded "><a href="types/int.html"><strong aria-hidden="true">2.1.2.</strong> int</a></li><li class="chapter-item expanded "><a href="types/real.html"><strong aria-hidden="true">2.1.3.</strong> real</a></li><li class="chapter-item expanded "><a href="types/string.html"><strong aria-hidden="true">2.1.4.</strong> string</a></li><li class="chapter-item expanded "><a href="types/function.html"><strong aria-hidden="true">2.1.5.</strong> function types</a></li></ol></li><li class="chapter-item expanded "><a href="types/sig.html"><strong aria-hidden="true">2.2.</strong> Signatures</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="types/list.html"><strong aria-hidden="true">2.2.1.</strong> list</a></li><li class="chapter-item expanded "><a href="types/dict.html"><strong aria-hidden="true">2.2.2.</strong> dictionaries</a></li><li class="chapter-item expanded "><a href="types/regex.html"><strong aria-hidden="true">2.2.3.</strong> regular expressions</a></li><li class="chapter-item expanded "><a href="seq/seq.html"><strong aria-hidden="true">2.2.4.</strong> sequences</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="debugging/index.html"><strong aria-hidden="true">3.</strong> Debugging</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="debugging/errors.html"><strong aria-hidden="true">3.1.</strong> Common Errors</a></li><li class="chapter-item expanded "><a href="debugging/hints.html"><strong aria-hidden="true">3.2.</strong> Debugging Hints</a></li></ol></li><li class="chapter-item expanded "><a href="concepts/index.html"><strong aria-hidden="true">4.</strong> Concepts</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/basic.html"><strong aria-hidden="true">4.1.</strong> Basics</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/eval.html"><strong aria-hidden="true">4.1.1.</strong> Evaluation</a></li><li class="chapter-item expanded "><a href="concepts/eeq.html"><strong aria-hidden="true">4.1.2.</strong> Extensional Equivalence</a></li><li class="chapter-item expanded "><a href="concepts/patternmatch.html"><strong aria-hidden="true">4.1.3.</strong> Pattern Matching</a></li></ol></li><li class="chapter-item expanded "><a href="concepts/recind.html"><strong aria-hidden="true">4.2.</strong> Recursion and Induction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/inductionintuition.html"><strong aria-hidden="true">4.2.1.</strong> Intuition</a></li><li class="chapter-item expanded "><a href="concepts/tail.html"><strong aria-hidden="true">4.2.2.</strong> Tail Recursion</a></li></ol></li><li class="chapter-item expanded "><a href="concepts/analysis.html"><strong aria-hidden="true">4.3.</strong> Asymptotic Analysis</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/workspan.html"><strong aria-hidden="true">4.3.1.</strong> Work and Span</a></li></ol></li><li class="chapter-item expanded "><a href="concepts/datatypes.html"><strong aria-hidden="true">4.4.</strong> Datatypes</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/poly.html"><strong aria-hidden="true">4.4.1.</strong> Parametric Polymorphism</a></li></ol></li><li class="chapter-item expanded "><a href="concepts/hofs.html"><strong aria-hidden="true">4.5.</strong> Higher Order Functions</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/curry.html"><strong aria-hidden="true">4.5.1.</strong> Currying and Partial Evaluation</a></li></ol></li><li class="chapter-item expanded "><a href="concepts/control.html"><strong aria-hidden="true">4.6.</strong> Control Flow</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/cps.html"><strong aria-hidden="true">4.6.1.</strong> Continuation Passing Style</a></li><li class="chapter-item expanded "><a href="concepts/exn.html"><strong aria-hidden="true">4.6.2.</strong> Exceptions</a></li></ol></li><li class="chapter-item expanded "><a href="concepts/mods.html"><strong aria-hidden="true">4.7.</strong> Modules</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/ascription.html"><strong aria-hidden="true">4.7.1.</strong> Ascription</a></li></ol></li><li class="chapter-item expanded "><a href="concepts/apps.html"><strong aria-hidden="true">4.8.</strong> Applications</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concepts/costgraphs.html"><strong aria-hidden="true">4.8.1.</strong> Cost graphs</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="examples/index.html"><strong aria-hidden="true">5.</strong> Examples</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="examples/basics.html"><strong aria-hidden="true">5.1.</strong> Basics</a></li><li class="chapter-item expanded "><a href="examples/recursion.html"><strong aria-hidden="true">5.2.</strong> Recursion &amp; Induction</a></li></ol></li><li class="chapter-item expanded "><a href="about.html">About</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">SML Help</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#welcome" id="welcome">Welcome!</a></h1>
<p>Welcome to <code>smlhelp.github.io</code>! The goal of this site is to provide a convenient
resource for learning functional programming, particularly in the language of
Standard ML. You'll find various guides and references about the SML type system
&amp; functional programming concepts, as well as some worked examples and tutorials.
Click on the navigation links on the left to get started!</p>
<h1><a class="header" href="#getting-started" id="getting-started">Getting Started</a></h1>
<h1><a class="header" href="#installing-smlnj" id="installing-smlnj">Installing SML/NJ</a></h1>
<h2><a class="header" href="#installing-smlnj-on-afs" id="installing-smlnj-on-afs">Installing SML/NJ on AFS</a></h2>
<p>To set up your SML/NJ environment on the Andrew File System (AFS), first you will need to log in to AFS.</p>
<p>You can do this by executing the command
<code>ssh &lt;andrew_id&gt;@unix.andrew.cmu.edu</code></p>
<p>You can do this from a terminal very straightforwardly on a Mac. If you are on a Windows machine, you may need to use an application such as Visual Studio Code or MobaXTerm to access a terminal.</p>
<p>Once you are in AFS, execute the command 
<code>/afs/andrew/course/15/150/bin/setup-path</code></p>
<p>Once the script has finished running, type in the command that it tells you to. It should look something like
<code>. '/afs/andrew.cmu.edu/usrc/&lt;andrew_id&gt;/.bashrc</code></p>
<p><strong>IMPORTANT:</strong> <em>Do not forget the . at the beginning!</em> This will cause the script to not work. </p>
<p>After finishing this, you should be able to type in <code>smlnj</code> from the command line and access the SML/NJ REPL.</p>
<h1><a class="header" href="#sml-syntax-cheatsheet" id="sml-syntax-cheatsheet">SML Syntax Cheatsheet</a></h1>
<h1><a class="header" href="#common-tasks-in-sml" id="common-tasks-in-sml">Common Tasks in SML</a></h1>
<h1><a class="header" href="#types--singatures" id="types--singatures">Types &amp; Singatures</a></h1>
<h1><a class="header" href="#types" id="types">Types</a></h1>
<p>Types are a very fundamental concept to Standard ML, and indeed, to functional programming in general. Most programming languages have some notion of type, with <code>int</code>, <code>float</code>, and data structures such as <code>array</code> being common examples, however they tend to be weakly enforced, only being verified at runtime. In SML, we employ a system of <em>strong typing</em> consisting of stricter typing rules, which allows us to catch errors earlier in program execution, at compile time.</p>
<h2><a class="header" href="#type-safety" id="type-safety">Type Safety</a></h2>
<p>Oftentimes, data is separated into types so that we can differentiate different kinds of data from each other. For instance, it makes no sense to add a <code>string</code> and an <code>int</code> - though certain programming languages will try to make sense of it. It is often the case that, when different data types are haphazardly combined, it is the result of an error - the philosophy behind SML's type system is disallow such intermingling. In SML, every expression and every function has a specified type, which governs what interactions are possible with other expressions. </p>
<p>Consider the following code fragment in Python:</p>
<pre><code class="language-python">def foo(x):
    if x == 2:
        return 1  
    elif x == &quot;bar&quot;:
        return True
    return None
</code></pre>
<p>What is the type of its output? The answer is &quot;it depends&quot;, as it is dependent on the value of <code>x</code> that is passed in. We could give <code>foo</code> any type of argument, and we can see that in the cases that we pass in <code>2</code> or <code>&quot;bar&quot;</code>, we could obtain an <code>int</code> or a <code>bool</code> as output, or even a <code>None</code> in any other case.</p>
<p>Then consider - is <code>foo(y) + 3</code> safe? Again, this is dependent on what the value of <code>y</code> is, but we see the same answer of &quot;it depends&quot;. In some cases, depending on what the program has done up to this point, it may be safe - this is in the case where <code>y</code> is <code>2</code>, in which case <code>foo(y) + 3</code> would just be <code>4</code>. But if it wasn't, we may end up trying to add <code>True</code> or <code>None</code> to <code>2</code>, which clearly doesn't make sense. While a contrived piece of code, type errors such as this spring up in code all the time. Whoever wrote this program likely didn't intend to try and add a non-int to <code>2</code>, but it can be tricky to reason about whether or not such an outcome is truly possible.</p>
<p>In SML, our philosophy will be to make such uncertanties impossible. We impose a certain degree of <em>determinism</em> to our programs, such that the types of each expression and each step of evaluation throughout our program have a definite type that is known to the program. If a program tries to execute some computation that would use the wrong type somewhere, or otherwise cause types to not match up, then we would call the program <em>ill-typed</em>, and it would be rejected before even evaluating. This period of verifying types is called <em>type-checking</em>, and occurs at <em>compile-time</em>, which stands opposed to <em>run-time</em>. Compile-time checking happens before the program is actually run, before any actual evaluation, and only upon passing the type-checking phase will the program actually execute.</p>
<h2><a class="header" href="#type-checking" id="type-checking">Type-Checking</a></h2>
<p>The most fundamental rule for type-checking is during function application, or the act of applying a function to its arguments. This is elaborated on further in the chapter on functions.</p>
<blockquote>
<p><strong>[APP]</strong> An expression <code>e1 e2</code> has type <code>t2</code> if and only if <code>e1 : t1 -&gt; t2</code> and <code>e2 : t1</code>.</p>
</blockquote>
<p>More specifically, for a function <code>f : t1 -&gt; t2</code>, if <code>x : t3</code> where <code>t3</code> is not the same type as <code>t1</code>, then the expression <code>f x</code> is ill-typed. In words, giving a function an argument that is not of the corresponding type to its input type is ill-typed, and will cause a program to reject at compile-time. We call an expression that does not encounter a type error <em>well-typed</em>.</p>
<p>The majority of type errors will occur as a consequence of this rule. Since functions have definite return types, it is very simple to check if a program type-checks - simply evaluate the <em>types</em> of the expressions and see if a type error is reached. The type-checking phase is agnostic to the specific values of expressions - when given an expression such as <code>1 + 2</code>, it simply sees two expressions of type <code>int</code> being passed into a function of type <code>int * int -&gt; int</code>, and thus knows that the result must be of type <code>int</code>, and that the entire expression is well-typed.</p>
<p>Because of this, the well-typedness of expressions is independent of any run-time errors that may occur. For instance, the expression <code>1 div 0</code> clearly cannot give back a value of type <code>int</code>, as division by 0 is undefined. Instead, during execution, <code>1 div 0</code> will raise the exception <code>Div</code>, and try to terminate execution of the program. From the perspective of type-checking, however, it has no way of knowing that the second argument of <code>div</code> is <code>0</code>, since it only looks at the types. As such, even though it will not return a value, the expression <code>1 div 0</code> is well-typed, and has type <code>int</code>.</p>
<h2><a class="header" href="#conclusion" id="conclusion">Conclusion</a></h2>
<p>SML's type system is a very powerful tool for ensuring the correctness of programs. The philosophy behind Standard ML is to push errors to compile-time, before a program is even run - in doing this, we can ensure that unexpected errors do not arise during run-time, long after we've already concluded that our code is correct. With strong typing and type-checking, we can guarantee that our code will be free of type errors, reducing the possibility of making mistakes. Later in this section, we will discuss some concrete types.</p>
<h1><a class="header" href="#bool" id="bool">Bool</a></h1>
<p><code>bool</code> is the SML type of booleans. The <code>bool</code> type supports the usual constructs of boolean logic and &quot;conditionals&quot; (<code>if</code> expressions). <code>bool</code> is also the type produced when evaluating (in)equality between values of (suitable) types. </p>
<h2><a class="header" href="#values" id="values">Values</a></h2>
<p>There are exactly two values of type <code>bool</code>, <code>true</code> and <code>false</code>.</p>
<pre><code class="language-sml">datatype bool = true | false
</code></pre>
<p>In addition to the constructs generally available in pattern matching (e.g. wildcards and identifier binding), booleans can be pattern-matched against using the constructors <code>true</code> and <code>false</code>.</p>
<pre><code class="language-sml">fun firstOrSecond ((x : int,y : int), true):int = x
  | firstOrSecond ((x,y), false) = y

val 2 = firstOrSecond((3,2),false)
</code></pre>
<p><code>bool</code> is pretty-printed by the <code>smlnj</code> REPL, so the actual values will display. This is demonstrated by the following <code>smlnj</code> REPL snippet.</p>
<pre><code class="language-sml">- val b = true orelse false;
val b = true : bool
</code></pre>
<h2><a class="header" href="#production" id="production">Production</a></h2>
<p>Some common functions which produce booleans:</p>
<pre><code class="language-sml">(op =)  : ''a * ''a -&gt; bool
(op &lt;&gt;) : ''a * ''a -&gt; bool  (* Inequality *)

(* All of the following are overloaded and also work on values of type real *)
(op &lt;)  : int * int -&gt; bool
(op &gt;)  : int * int -&gt; bool
(op &lt;=) : int * int -&gt; bool
(op &gt;=) : int * int -&gt; bool
</code></pre>
<h2><a class="header" href="#elimination" id="elimination">Elimination</a></h2>
<p>The principal use of booleans is for evaluating one of two possible expressions, conditional on a value of type <code>bool</code>:</p>
<pre><code class="language-sml">(* Evaluates to 5 *)
val res1 = if true then 5 else 2

(* Evaluates to 7 *)
val res2 = if false then 3+3 else 7
</code></pre>
<p>Note that the expression between <code>then</code> and <code>else</code> (the &quot;then branch&quot;) has the same type as the expression after the <code>else</code> (the &quot;else branch&quot;). This is necessary: the SML typechecker does not evaluate expressions, and so does not &quot;know&quot; that, for instance, <code>if false then e1 else e2</code> will always reduce to <code>e2</code>. As far as the typechecker knows, <code>if false then e1 else e2</code> could reduce to <code>e1</code>. So, in order for the typechecker to be able to assign a type to the expression <code>if false then e1 else e2</code>, it must be the case that <code>e1</code> and <code>e2</code> have the same type. More formally, </p>
<blockquote>
<p>[If-Then]  An expression <code>if b then e1 else e2</code> is well-typed (with type <code>t</code>) 
if and only if 
<code>b : bool</code> and <code>e1 : t</code> and <code>e2 : t</code>.</p>
</blockquote>
<p>It is worth noting that <code>if b then e1 else e2</code> is equivalent to the following expression, written using SML's <code>case</code> syntax.</p>
<pre><code class="language-sml">    case b of
      true =&gt; e1
    | false =&gt; e2
</code></pre>
<p>Which is also equivalent to</p>
<pre><code class="language-sml">    (fn true =&gt; e1 | false =&gt; e2) b
</code></pre>
<p><strong>NOTE:</strong> It's important to note that, in the evaluation of the expression <code>if true then e1 else e2</code>, the expression <code>e2</code> is <em>never</em> evaluated (and, analogously, <code>e1</code> never is evaluated in <code>if false then e1 else e2</code>). This is most evident when we look at the third syntax (with the lambda function): SML does not evaluate the body of a function <em>until the function is called</em>. So when <code>(fn true =&gt; e1 | false =&gt; e2)</code> gets applied to, say, <code>true</code>, then the evaluation steps immediately to <code>e1</code>, without ever evaluating <code>e2</code>. This point is explored more in a question below.</p>
<h2><a class="header" href="#combination" id="combination">Combination</a></h2>
<p><code>bool</code> is an equality type, and may therefore be compared with <code>=</code>, producing another <code>bool</code>.</p>
<pre><code class="language-sml">val true = (true = true)
val false = (true = false)
val false = (false &lt;&gt; false)
</code></pre>
<p><code>bool</code> also comes equipped with the usual boolean operators,</p>
<pre><code class="language-sml">val true = true andalso true   (* andalso keyword, logical and *)
val true = false orelse true   (* orelse keyword, logical or *)
val false = not true           (* not:bool -&gt; bool, logical negation *)
</code></pre>
<p>An important note about <code>andalso</code> and <code>orelse</code>: the evaluation of <code>b1 andalso b2</code> has a behavior known as <em>short-circuiting</em>:<sup>[1]</sup> when evaluating this expression, SML will first attempt to evaluate <code>b1</code>. If <code>b1</code> raises an exception or loops behavior, then that will be the behavior of <code>b1 andalso b2</code> as a whole. If <code>b1</code> reduces down to the value <code>true</code>, then SML will then attempt to evaluate <code>b2</code>. However, if <code>b1</code> evaluates to the value <code>false</code>, then SML will <em>not evaluate <code>b2</code></em>. This is exhibited in the following code snippet.</p>
<pre><code class="language-sml">(* loops forever on any input *)
fun loop (x:int):bool = loop x

(* Evaluates to the value false, and doesn't loop *)
val false = false andalso (loop 3)
</code></pre>
<h2><a class="header" href="#from-the-structure" id="from-the-structure">From the Structure</a></h2>
<p>The structure <code>Bool</code> is bound as part of the SML Basis. In addition to what's already been mentioned, it includes the utility function</p>
<pre><code class="language-sml">	Bool.toString : bool -&gt; string
</code></pre>
<p>This is useful (for instance) for print-debugging the value of a <code>bool</code>-valued variable.</p>
<h2><a class="header" href="#questions-to-consider" id="questions-to-consider">Questions to Consider</a></h2>
<ol>
<li>Why are the following expressions <em>not</em> equivalent?</li>
</ol>
<pre><code class="language-sml">    (if b then e1 else e2)

    (fn (x,y) =&gt; if b then x else y) (e1,e2)
</code></pre>
<ol start="2">
<li>Why are the following expressions <em>not</em> equivalent?</li>
</ol>
<pre><code class="language-sml">    b1 andalso b2

    (fn (v1,v2) =&gt; v1 andalso v2) (b1,b2)
</code></pre>
<h4><a class="header" href="#footnotes" id="footnotes">Footnotes</a></h4>
<p>[1]: This is why <code>andalso</code> and <code>orelse</code> are designated as <em>keywords</em> above: they are <em>not</em> infixed functions of type <code>bool*bool-&gt;bool</code>. Functions cannot exhibit this kind of &quot;shortcircuiting&quot; (evaluating one of their arguments and then deciding whether to evaluate the other): the integer addition <code>(op +) : int*int -&gt; int</code> must have both of its arguments fully evaluated before proceeding to add them. The keywords <code>andalso</code> and <code>orelse</code> must be built-in to the SML evaluator to achieve shortcircuiting.</p>
<h1><a class="header" href="#int" id="int">Int</a></h1>
<p><code>int</code> is the SML type of integers.</p>
<h2><a class="header" href="#values-1" id="values-1">Values</a></h2>
<p>The underlying representation of integers can be likened to the following:</p>
<pre><code class="language-sml">datatype int = ... | ~2 | ~1 | 0 | 1 | 2 | ...
</code></pre>
<p>This signifies that the type <code>int</code> is inhabited by infinitely many values, all corresponding to whole numbers. In particular, every integer forms its own <em>constant constructor</em> for the <code>int</code> type, meaning that they each individually can be pattern matched upon. Note that the use of <code>~</code> above denotes negativity. Additionally, <code>~</code> is a valid function of type <code>int -&gt; int</code> that negates a number.</p>
<p>While in practice, computers can only represent a finite number of integers, for the purposes of this class we will generally assume the integers to be unbounded. This means that we can do induction on SML integers in exactly the same way as we would do induction on the natural numbers, and that we do not have to worry about the consequences of edge case behavior. This allows us to ignore pedantic implementation details and explore mathematically interesting properties of programs.</p>
<h2><a class="header" href="#production-1" id="production-1">Production</a></h2>
<p>Integers have all the familiar arithmetic operations available to them. Note that some of these functions are also overloaded to work with <code>real</code> types - this is further discussed in the Real page.</p>
<pre><code class="language-sml">(op +)   : int * int -&gt; int
(op -)   : int * int -&gt; int
(op *)   : int * int -&gt; int
(op div) : int * int -&gt; int
(op mod) : int * int -&gt; int
</code></pre>
<p>All of these functions are <em>infixed</em>, so instead of being applied as <code>+(2, 3)</code>, we write <code>2 + 3</code>. Additionally, <code>div</code> and <code>mod</code> are not defined when the second argument is 0, and will raise a <code>Div</code> exception.</p>
<h2><a class="header" href="#combination-1" id="combination-1">Combination</a></h2>
<p>Integers are also eligible for comparison, including equality and inequality. (In other words, integers are an <em>equality type</em>).</p>
<pre><code class="language-sml">(op =)  : int * int -&gt; bool
(op &lt;&gt;) : int * int -&gt; bool (* Inequality *)

(op &lt;)  : int * int -&gt; bool
(op &gt;)  : int * int -&gt; bool
(op &lt;=) : int * int -&gt; bool
(op &gt;=) : int * int -&gt; bool
</code></pre>
<h2><a class="header" href="#from-the-structure-1" id="from-the-structure-1">From the Structure</a></h2>
<p>The structure <code>Int</code> is bound as part of the SML Basis. It includes helpful functions such as</p>
<pre><code class="language-sml">Int.toString : int -&gt; string
Int.compare  : int * int -&gt; order
Int.min      : int * int -&gt; int
Int.max      : int * int -&gt; int
</code></pre>
<p>where <code>Int.toString</code> is the function that returns the string representation of a given integer, and <code>Int.compare</code> has return type <code>order</code>, which is inhabited only by values <code>LESS</code>, <code>EQUAL</code>, and <code>GREATER</code>. <code>Int.compare (x, y)</code> returns <code>LESS</code> only if x &lt; y, <code>EQUAL</code> if x = y, and <code>GREATER</code> if <code>x &gt; y</code>. Additionally, <code>Int.min</code> and <code>Int.max</code> are just the corresponding min and max functions for integers.</p>
<h1><a class="header" href="#real" id="real">Real</a></h1>
<p><code>real</code> is the SML type of real or floating-point numbers. As in other programming languages, reals in SML are restricted to finite machine representations, which means that they cannot represent every real number with perfect precision. For this reason, generally in this course we will prefer the use of <code>int</code>s when performing numeric operations.</p>
<h2><a class="header" href="#values-2" id="values-2">Values</a></h2>
<p>A real number is a sequence of numbers, followed by a decimal point, followed by another sequence of numbers. This includes examples such as <code>15.150</code>, <code>1.0</code>, and <code>3.14159</code>. Reals are noteworthy in that they are not <em>equality types</em>, which means that they cannot be compared for equality with the <code>=</code> operator. In addition, they cannot be pattern matched upon. This means that when designing programs with specific behavior based on equality with a specific real number, they should instead be written to operate within some <em>degree of precision</em> of the real number in question. For instance:</p>
<pre><code class="language-sml">val equalThreshold = 0.000001
fun isZero (x : real) : bool = Real.abs x &lt; equalThreshold
</code></pre>
<p>This function simply prespecifies a (small) range, within which a number can be considered to be &quot;equal&quot; to 0. It uses the function <code>Real.abs</code> to check if the real number in question is within that threshold of zero, in either direction. In this way, we can approximate some test for equality, up to some degree of acceptable precision.</p>
<h2><a class="header" href="#production-2" id="production-2">Production</a></h2>
<p>Real numbers similarly have access to some of the basic arithmetic operations as integers. In particular, they have:</p>
<pre><code class="language-sml">(op +) : real * real -&gt; real
(op -) : real * real -&gt; real
(op *) : real * real -&gt; real
(op /) : real * real -&gt; real
</code></pre>
<p>Note that all but the last operator are also defined to work on <code>int</code> types. This may seem to violate type safety, however this is just an example of those functions being <em>overloaded</em>. There are two &quot;copies&quot; of, for instance, the <code>+</code> operator - one that has type <code>int * int -&gt; int</code> and one with type <code>real * real -&gt; real</code>. Notably, however, it only works on either both ints or both reals - it is not defined on both. As such, SML can infer from its arguments whether it should use the <code>int</code> or the <code>real</code> variant, and similarly for <code>-</code> and <code>*</code>. <code>div</code>, however, is only defined for integers - <code>/</code> is the counterpart for division on the real numbers.</p>
<h2><a class="header" href="#combination-2" id="combination-2">Combination</a></h2>
<p>While not defined for equality, reals can still be compared to one another.</p>
<pre><code class="language-sml">(op &lt;)  : real * real -&gt; bool
(op &gt;)  : real * real -&gt; bool
(op &lt;=) : real * real -&gt; bool
(op &gt;=) : real * real -&gt; bool
</code></pre>
<p>These operations are similarly overloaded, and will also work on integers.</p>
<h2><a class="header" href="#from-the-structure-2" id="from-the-structure-2">From the Structure</a></h2>
<p>The structure <code>Real</code> is bound as part of the SML Basis. It has access to a few useful functions, including:</p>
<pre><code class="language-sml">Real.toString : real -&gt; string
Real.compare  : real * real -&gt; order
Real.abs      : real -&gt; real
</code></pre>
<p>where <code>Real.toString</code> is the standard function that transforms a real number into its corresponding string representation, <code>Real.compare</code> on two reals returns <code>LESS</code>, <code>EQUAL</code>, or <code>GREATER</code> depending on their relative magnitudes, and <code>Real.abs</code> returns the absolute value of the real number in question.</p>
<h1><a class="header" href="#string" id="string">String</a></h1>
<p><code>string</code> is the SML type of ordered collections of characters. </p>
<h2><a class="header" href="#values-3" id="values-3">Values</a></h2>
<p>Any valid string literal is a value of type <code>string</code>. This means that examples such as <code>&quot;functional&quot;</code>, <code>&quot;15-150&quot;</code>, and <code>&quot;\n&quot;</code> are all valid strings, forming their own constant constructors that can thus be pattern matched upon.</p>
<pre><code class="language-sml">fun courseToNum (&quot;15-150&quot; : string) : int = 15150
  | courseToNum (&quot;15-151&quot; : string) : int = 15151
  | courseToNum (&quot;15-122&quot; : string) : int = 15122
</code></pre>
<h2><a class="header" href="#production-3" id="production-3">Production</a></h2>
<p>Numerous types have their own <code>toString</code> functions that allow them to be easily converted to their string representations, including:</p>
<pre><code class="language-sml">Bool.toString : bool -&gt; string
Int.toString  : int -&gt; string
Real.toString : real -&gt; string
</code></pre>
<h2><a class="header" href="#combination-3" id="combination-3">Combination</a></h2>
<p>Strings can be combined by means of the <code>^</code> operator, or &quot;concatenation&quot;. <code>^</code> takes two strings and joins them together, without creating any spaces. As such, if neither string contains spaces, then the resulting string will be attached directly. Specifically, the result of an operation such as <code>&quot;functional&quot; ^ &quot;programming&quot;</code> will be <code>&quot;functionalprogramming&quot;</code>.</p>
<pre><code class="language-sml">(op ^) : string * string -&gt; string
</code></pre>
<h2><a class="header" href="#from-the-structure-3" id="from-the-structure-3">From the Structure</a></h2>
<p>The structure <code>String</code> is bound as part of the SML Basis. It contains several useful functions for dealing with strings, such as:</p>
<pre><code class="language-sml">String.explode : string -&gt; char list
String.implode : char list -&gt; string
</code></pre>
<p><code>String.explode</code> takes a string and converts it to a list of its constituent characters, in order as they appear in the string. <code>String.implode</code> is the opposite, taking in a list of characters and joining them to form a string. This means that:</p>
<pre><code class="language-sml">val [#&quot;1&quot;, #&quot;5&quot;, #&quot;1&quot;, #&quot;5&quot;, #&quot;0&quot;] = String.explode &quot;15150&quot;
val &quot;15150&quot; = String.implode [#&quot;1&quot;, #&quot;5&quot;, #&quot;1&quot;, #&quot;5&quot;, #&quot;0&quot;]
</code></pre>
<p>Note that the use of <code>#</code> is to denote that each element of the list is a <code>char</code> type, as opposed to a <code>string</code> of length 1.</p>
<h1><a class="header" href="#functions" id="functions">Functions</a></h1>
<p>Functions are a familiar concept in programming. In most languages, functions seem to capture a notion of a list of instructions to be carried out, with each invocation of the function resulting in another round of executing its instructions. In this class, however, we will take another perspective on functions - one that identifies the function more with the values that it outputs than the instructions that it executes.</p>
<h2><a class="header" href="#what-is-a-function" id="what-is-a-function">What is a Function?</a></h2>
<p>What is a function? To most seasoned programmers, the definition given in the above section seems to be the most obvious. A function (or subroutine) is simply identified with the instructions that it executes, which have some <em>effect</em> on the state of the program as a whole, such as incrementing some variable, or setting some flag. </p>
<p>Before most programmers were programmers, however, they had a different notion of a function. To a mathematician, a function is something else entirely. Instead of being an algorithmic sequence of instructions, a function is simply an entity that maps inputs to outputs - for example, (f(x) = x + 1). Something rather notable is that mathematical functions are <em>pure</em> - given the same input, they always return the same output. So while it is a valid question in programming to ask how a function's behavior changes over time, this is a nonsensical question in terms of mathematical functions.</p>
<p>To be more concrete, let us consider a Python program.</p>
<pre><code class="language-python">x = 0
def f(y):
    x += 1
    return x + y
</code></pre>
<p>This program instantiates a variable <code>x</code> outside the scope of the function <code>f</code> (which takes a single argument <code>y</code>), and the behavior of <code>f</code> is to increment the value of <code>x</code>, then return the sum of <code>x</code> and <code>y</code>. What we would find is that the first time that we run <code>f(0)</code>, for instance, we obtain <code>1</code>. The second time that we run <code>f(0)</code>, it will return <code>2</code>, and so on and so forth. We cannot even say that <code>f(0) = f(0)</code>! The output behavior of this function changes every time that it is run. This makes it difficult to reason about the function - in order to do so, we must know the number of times that it has been called before, at a given step in the program. While this is a fairly tame example, this problem only compounds with more complicated functions.</p>
<p>Clearly, this function is <em>impure</em>. Can we do better?</p>
<h2><a class="header" href="#function-types-and-function-application" id="function-types-and-function-application">Function Types and Function Application</a></h2>
<p>So far we have seen basic types such as <code>int</code> and <code>string</code>, among others. Functions allow us to compose types in new ways.</p>
<p>In SML, we denote the type of a function that has input type <code>t1</code> and output type <code>t2</code> (for some arbitrary, fixed <code>t1</code> and <code>t2</code>) to be <code>t1 -&gt; t2</code>. By SML's strict typing rules, functions of type <code>t1 -&gt; t2</code> can <em>only</em> take in inputs of type <code>t1</code> and return outputs of type <code>t2</code>, for any types <code>t1</code> and <code>t2</code>. Additionally, we write <code>e1 e2</code> for the expression consisting of the function <code>e1</code> being given as input the expression <code>e2</code> (so we may write the mathematical function (f(x)) instead as <code>f x</code>).</p>
<blockquote>
<p><strong>[APP]</strong> An expression <code>e1 e2</code> has type <code>t2</code> if and only if <code>e1 : t1 -&gt; t2</code> and <code>e2 : t1</code>.</p>
</blockquote>
<p>We call the above rule [APP] since it concerns the types of expressions during <em>function application</em>, or the process of applying a function to an argument. </p>
<p>Note that a function must always have type <code>t1 -&gt; t2</code> (for some types <code>t1</code> and <code>t2</code>, though <code>t1</code> and <code>t2</code> may be complicated types in their own right). As such, all functions in SML can only take in <em>one</em> input - though the input type <code>t1</code> may be one that &quot;contains&quot; multiple values. For instance, a function may have type <code>int * int -&gt; bool</code>. For such a function, it takes in only <em>one</em> argument (a tuple containing two integers).</p>
<h2><a class="header" href="#functions-in-sml" id="functions-in-sml">Functions in SML</a></h2>
<p>We can declare a function with the <code>fun</code> keyword.</p>
<pre><code class="language-sml">fun fact (0 : int) : int = 1
  | fact (n : int) : int = n * fact (n - 1)
</code></pre>
<p>The above example serves to initialize a function that computes the factorial function, and then bind it to the identifier <code>fact</code>. Function declarations create a <em>closure</em> which includes all bound variables in the scope of the function when it was declared, so the behavior of <code>fact</code> will always be as if it was in the same environment as when it was first declared. As such, we can also declare functions such as:</p>
<pre><code class="language-sml">val x = 1
fun addX (n : int) : int = n + x
val x = 2
</code></pre>
<p>When <code>addX</code> is bound, it is bound in a closure that includes the binding of the value <code>1</code> to the identifier <code>x</code> (we may denote this as <code>[1/x]</code>). As such, even though the body of <code>addX</code> refers to the identifier <code>x</code>, it is not affected by the later re-binding of the value of <code>x</code>, since it only matters what the value of <code>x</code> was when <code>addX</code> was first bound. Seen in this way, then, reasoning about functions which use bound variables is very intuitive - you simply have to look up for the most recent time that that variable was bound.</p>
<p>We also can use <em>anonymous lambda expressions</em> to bind functions. These are denoted by the <code>fn</code> keyword, and are called lambda expressions for historical reasons having to do with a model of computation called the <em>lambda calculus</em>. For instance, we can declare:</p>
<pre><code class="language-sml">val addOne : int -&gt; int = fn x =&gt; x + 1
</code></pre>
<p>Lambda expressions can also be <em>multi-clausal</em>, by pattern matching to multiple different clauses. For instance, we can define the following function, which simply returns true when given 0 and 1, and false otherwise.</p>
<pre><code class="language-sml">val isBinary : int -&gt; bool = fn 0 =&gt; true | 1 =&gt; true | _ =&gt; false
</code></pre>
<p>Note that the right hand side of this declaration is an expression in its own right, and can be used independently of just being bound. The above binding simply binds the anonymous lambda expression (which simply increments an integer) to the identifier <code>addOne</code>. We could also do the following binding:</p>
<pre><code class="language-sml">val two : int = (fn x =&gt; x + 1) 1
</code></pre>
<p>where we bind the result of evaluating the expression <code>(fn x =&gt; x + 1) 1</code> to the identifier <code>two</code>. Clearly, this expression evaluates to <code>2</code>, as <code>1</code> is substituted in for the local variable <code>x</code>, and then simply summed with <code>1</code>. </p>
<p><strong>NOTE:</strong> <code>fun</code> and <code>fn</code> differ in that functions declared with <code>fun</code> can be recursive, whereas val bindings using <code>fn</code> <em>cannot</em>. As such, while we can define the function <code>fact</code> as we did above, using <code>fun</code>, the following code <em>does not</em> work:</p>
<pre><code class="language-sml">(* DOES NOT WORK *)
val fact : int -&gt; int = fn 0 =&gt; 1 | n =&gt; n * fact (n - 1)
</code></pre>
<p>We will explore later on in the course what lambda expressions are useful for. In the meantime, usage of <code>fun</code> is sufficient to declare any functions that you may need.</p>
<p>It is also important to note that SML is an <em>eager</em> language, or <em>call-by-value</em>. This means that functions evaluate their arguments before stepping into their function bodies. This is explored more in the article on evaluation.</p>
<h1><a class="header" href="#signatures" id="signatures">Signatures</a></h1>
<h1><a class="header" href="#list" id="list">List</a></h1>
<p>Lists are the SML type of ordered collections of objects. Notably, you can create lists of any kind of object, so <code>int list</code>, <code>string list</code>, and <code>bool list</code> are all valid types. <code>list</code> on its own is a type constructor (meaning that it makes new types out of old types), so it is not a valid type by itself, however. Lists are not, however, the same as arrays - they do not have constant-time access to any given index of the list. Indeed, they are best thought of as not analogous to arrays in other languages at all. Instead, you only have access to the elements located at the very beginning of the list, the <em>head</em>. Additionally, lists are more <em>restricted</em> than data structures in some other languages - a given list has a fixed type for its elements. All of the elements in a list must be of the same type. For the purposes of this document, we will discuss only int lists.</p>
<h2><a class="header" href="#values-4" id="values-4">Values</a></h2>
<p>We write lists as a sequence of integers, separated by commas, all enclosed with two square brackets. So then we have valid int lists as <code>[1, 2, 3]</code>, <code>[1, 5, 1, 5, 0]</code>, and <code>[]</code>, with the latter representing the empty list. We also refer to the empty list as <em>nil</em> (in addition, you can type <code>nil</code> instead of <code>[]</code> in code). </p>
<p>The other essential component to lists is what is known as the <code>::</code> operator, referred to as &quot;cons&quot;. Cons can be used as a constructor for any fixed type of list, so we say that for any given type <code>t</code>:</p>
<pre><code class="language-sml">(op ::) : t * t list -&gt; t list
</code></pre>
<p>Cons takes in a value <code>v</code> of type <code>t</code> and <code>t list</code>, and prepends <code>v</code> to the front of the given list. For ints in particular, we have that <code>1 :: [2, 3]</code> steps to <code>[1, 2, 3]</code>. Additionally, cons is <em>right-associative</em>. This means that in a continuous stream of applications of cons, they are evaluated from <em>right-to-left</em>. This means that <code>1 :: 2 :: 3 :: []</code> is implicitly denoting <code>1 :: (2 :: (3 :: []))</code>, as the calls to cons associate to the right. So, similarly to before, a <code>1 :: [2, 3]</code>, <code>[1, 2, 3]</code>, and <code>1 :: 2 :: 3 :: []</code> are exactly equivalent, and denote the same list.</p>
<p>Cons is also a <em>constructor</em>, meaning that it can be used to pattern match and deconstruct lists. As such, we can write basic functions to compute the length of a list as follows:</p>
<pre><code class="language-sml">(* length : int list -&gt; int *)
(* REQUIRES: true *)
(* ENSURES: length L ==&gt; the length of L *)
fun length ([] : int list) : int = 0
  | length (x::xs : int list) : int = 1 + length xs
</code></pre>
<p>Given a non-empty list, this function simply binds the first element of the list to the identifier <code>x</code>, discards it, and then recursively calls <code>length</code> to find the length of the remaining list <code>xs</code>, adding 1 to the result.</p>
<p>The definition of an int list thus corresponds to:</p>
<pre><code class="language-sml">datatype int list = [] | :: of int * int list
</code></pre>
<p>where an int list can either be the empty list <code>[]</code>, or it can be <code>::</code> of a first element and the rest of the list (where <code>::</code> is an infix operator, so instead of being written as <code>::(x, xs)</code>, we have <code>x :: xs</code>). Note that this is not actually valid syntax, but you can think of the definition of int lists in this way.</p>
<h2><a class="header" href="#motivation" id="motivation">Motivation</a></h2>
<p>Compared to other data structures, lists seem to have numerous disadvantages. As mentioned previously, they do not possess constant-time indexing like arrays in other languages - there is no way to instantly get the ith element of a list easily. Instead, you must &quot;cons off&quot; all the elements in front of that item in order to retrieve it - if you want to remove that item from the list, then you have to put the preceding elements <em>back</em> as well (and in the right order!). Lists are also inherently sequential - you cannot access multiple elements at one time. </p>
<p>The reason why we choose lists is that they have very nice mathematical properties. These &quot;disadvantages&quot; in the previous paragraph become strengths, when viewed in a certain manner. Lists are powerful for their simple, inductive definition (as shown in the previous section), which is sufficiently powerful to characterize many important principles in this class. Additionally, they are <em>persistent</em>, meaning that they cannot be mutated - any change to a list simply creates a new one instead, which is a very desirable property to have in functional programs. Though the interfacing behavior with these lists is limited, we will write programs where this limitation matters less. Our hope is that, throughout this course, you can begin to see that there is an elegance in simplicity.</p>
<blockquote>
<p><strong>[Case Study: Sorted Lists]</strong></p>
<p>Sorting is an important principle in computer science. Whether it's binary search trees or cataloguing data, sorting is a very prevalent concept when it comes to making algorithms more efficient. It's not always the most easy to reason about, however - how would you be able to formally prove that a sorting algorithm works? In this regard, lists turn out to have some very nice properties.</p>
<blockquote>
<p><strong>Definition : Sorted Int Lists</strong></p>
<ol>
<li><code>[] : int list</code> is sorted.</li>
<li>The singleton int list is sorted.</li>
<li>If <code>L : int list</code> is sorted, then if <code>x : int</code> is less than or equal to the first element of <code>L</code>, then <code>x :: L</code> is sorted.</li>
</ol>
</blockquote>
<p>This definition is naturally inductive, and follows very easily from the definition of sorting. In addition, it goes hand-in-hand with how we define lists - building them up from smaller parts one-by-one. Seen in this way, reasoning about and proving whether a list is sorted becomes very easy.</p>
</blockquote>
<h2><a class="header" href="#combination-4" id="combination-4">Combination</a></h2>
<p>We have seen that cons is essential for constructing lists, and for deconstructing the constituent elements that comprise a given list. What about when dealing with multiple lists? We might want to <em>combine</em> the elements from several lists at once. A standard function for doing so is called the <code>@</code> operator, or &quot;append&quot;.</p>
<pre><code class="language-sml">infix @
fun ([] : int list) @ (R : int list) : int list = R
  | (l::ls : int list) @ (R : int list) : int list = l :: (ls @ R)
</code></pre>
<p>(Note that this is valid syntax to declare an infix function <code>@</code>, it just looks a little different than what we've seen thus far. In this case, we put the function name <em>between</em> the arguments).</p>
<p>This function essentially just takes off all the elements from the left list, then begins to add them back onto the right list. It is also infix, which means that the result of <code>[1, 2] @ [3, 4]</code> is <code>[1, 2, 3, 4]</code>, and in the function's code, <code>ls @ R</code> just means the resulting list from appending <code>ls</code> to <code>R</code>.</p>
<h2><a class="header" href="#questions-to-consider-1" id="questions-to-consider-1">Questions to Consider</a></h2>
<ol>
<li>
<p>In the code above, why does <code>@</code> not reverse the left list?</p>
</li>
<li>
<p>How might you inductively define a list whose elements all satisfy some property <em>P</em>?</p>
</li>
<li>
<p>Write an SML function that reverses a list. </p>
</li>
</ol>
<h1><a class="header" href="#dictionaries" id="dictionaries">Dictionaries</a></h1>
<h1><a class="header" href="#regular-expressions" id="regular-expressions">Regular Expressions</a></h1>
<h1><a class="header" href="#sequences" id="sequences">sequences</a></h1>
<h1><a class="header" href="#debugging" id="debugging">Debugging</a></h1>
<h1><a class="header" href="#common-errors" id="common-errors">Common Errors</a></h1>
<h1><a class="header" href="#debugging-hints-and-strategies" id="debugging-hints-and-strategies">Debugging Hints and Strategies</a></h1>
<h1><a class="header" href="#concepts" id="concepts">Concepts</a></h1>
<h1><a class="header" href="#basics" id="basics">Basics</a></h1>
<p>Standard ML is a <em>functional</em> programming language, meaning that we eschew the use of <em>side effects</em> and <em>state changes</em> to obtain programs that are easy to reason about, analogous to reasoning about mathematical expressions. Similarly to mathematics, we perform operations and view computation as a process of <em>simplification</em> (or <em>reduction</em>, as we will more commonly name it). Seen in this way, computation becomes an elaborate series of expression evaluations, and it is this concept that will permeate the course. In these notes, we will go further in detail about the basic concepts of SML.</p>
<h1><a class="header" href="#evaluation" id="evaluation">Evaluation</a></h1>
<p>Evaluation is a commonplace idea. No matter what programming language you are in, it is a customary concept to invoke subroutines in order to obtain some kind of <em>final result</em>, which can be further used in order to achieve some later goal. To obtain such a result, however, programs must perform certain computations and carry out certain steps - in other words, they must <em>evaluate</em>. Ultimately, programs are complicated constructs whose main goal is to compute some value or achieve some effect - we will focus mainly on the first case here. </p>
<h2><a class="header" href="#expressions-and-values" id="expressions-and-values">Expressions and Values</a></h2>
<p>Expressions in Standard ML are akin to mathematical expressions. They are built up from applications of certain operations, being subject to certain simplification rules that can be used to obtain a final answer. For instance, we would consider <code>2 + 2</code> an expression, similarly to other examples such as <code>1 div 0</code> and <code>Int.toString 2</code>.</p>
<p>The most fundamental building blocks in Standard ML are <em>values</em>. Values are the primordial units of a given type, being irreducible to any further simplified form. When trying to answer some computational problem, it is usually the case that we are looking for some kind of &quot;answer&quot;. As such, values are important to obtain, as we are usually looking for some kind of answer in &quot;simplest terms&quot;. Values in SML emcompass examples such as <code>2</code>, <code>true</code>, <code>&quot;foo&quot;</code>, <code>[1, 2, 3]</code> and <code>fn x =&gt; x + 1</code>.</p>
<blockquote>
<p><strong>[Value]</strong> A value is an expression <code>e</code> such that, for all <code>e'</code> such that <code>e ==&gt; e'</code>, <code>e' = e</code>. In other words, a value is an expression that only reduces to itself - there is no pending computation left to be done.</p>
</blockquote>
<p><strong>NOTE:</strong> The meaning of <code>==&gt;</code> in the above definition is <em>reduction</em>, which is further explained below. </p>
<p>A noteworthy distinction to make is that certain language constructs, such as an if-then-else expression, let-in-end expression, or case expression, are in fact <em>expressions</em>. This means that they can be passed around and evaluated just like any other expression. So for instance, the following code is a valid expression:</p>
<pre><code class="language-sml">(let
    val x = 5
in 
    x
end) + 2
</code></pre>
<p>and has the value of <code>7</code>. Similarly, the following code is also an expression:</p>
<pre><code class="language-sml">(if true then 15 else 150) * 2
</code></pre>
<p>and has a value of <code>30</code>. </p>
<h2><a class="header" href="#reduction" id="reduction">Reduction</a></h2>
<p>We now define a notion of <em>reduction</em>, which corresponds to our notion of simplification. We write that <code>e ==&gt; e'</code> if the expression <code>e</code> <em>reduces to</em> the expression <code>e'</code>, which means that <code>e</code> produces <code>e'</code> from zero or more applications of some simplifying rule. For instance, we may say that <code>2 + 2 ==&gt; 4</code>, since by applying the function <code>(op +)</code>, we obtain <code>4</code>. Furthermore, we may say that <code>if true then &quot;good&quot; else &quot;bad&quot; ==&gt; &quot;good&quot;</code> by evaluation of the if-then-else expression, since the predicate (in this case <code>true</code>) is true.</p>
<p><strong>NOTE:</strong> <code>==&gt;</code> is <em>not</em> valid SML code, it is simply our shorthand for the idea of reduction.</p>
<blockquote>
<p><strong>[Valuable]</strong> An expression <code>e</code> is <em>valuable</em> if there exists a value <code>v</code> such that <code>e ==&gt; v</code>. Note that all values are by definition valuable.</p>
</blockquote>
<p>So valuable expressions include <code>2 + 2</code>, <code>4</code>, and <code>if true then 4 else 2</code> (and in fact all reduce to the same value!). An example of a <em>non</em>-valuable expression is <code>1 div 0</code>, which raises an exception <code>Div</code> when evaluated (since division by zero is undefined). Additionally, if we consider the following code fragment:</p>
<pre><code class="language-sml">fun loop (x : int) : int = loop x
</code></pre>
<p>This defines a function <code>loop : int -&gt; int</code> that loops forever, since it continuously calls itself forever. Thus, <code>loop x</code> for any <code>x : int</code> is also a non-valuable expression, since it never reduces down to a value. </p>
<p>In fact, what we will see is that this behavior is sufficient to characterize <em>all</em> well-typed expressions. We summarize it in the following:</p>
<blockquote>
<p><strong>[Behavior of Well-Typed Expressions]</strong> For any well-typed expression <code>e</code>, it either:</p>
<ol>
<li>
<p>Reduces to a value</p>
</li>
<li>
<p>Loops forever</p>
</li>
<li>
<p>Raises an exception</p>
</li>
</ol>
</blockquote>
<h2><a class="header" href="#eager-evaluation" id="eager-evaluation">Eager Evaluation</a></h2>
<p>SML is an <em>eagerly evaluated</em><sup>[1]</sup> language. This stands opposed to other paradigms such as <em>lazy</em> evaluation, which is exhibited in languages such as Haskell. In an eagerly evaluated language, we evaluate arguments of functions even if we may not need them. While this arguably may be &quot;wasteful&quot; in some cases, we will find that this greatly simplifies work/span analysis, among other benefits.</p>
<blockquote>
<p><strong>[Eager Evaluation]</strong> In an eagerly evaluated language, arguments of functions are evaluated <em>before</em> stepping into the body of a function. For a function <code>f</code> and valuable expression <code>e</code>, when evaluating the expression <code>f e</code>, first <code>e</code> is evaluated to obtain the value <code>v</code> such that <code>e ==&gt; v</code>, then <code>f v</code> is evaluated.</p>
</blockquote>
<p>As an example of this, consider the function <code>fn x =&gt; x + 1</code>. If we were to try and evaluate <code>(fn x =&gt; x + 1) (2 * 3)</code>, first we would need to evaluate the function's arguments, that being <code>2 * 3</code>. As such, this entire expression would reduce to <code>(fn x =&gt; x + 1) 6</code>, which is <code>7</code>.</p>
<p>In an example like the previous one, it doesn't particularly matter where we evaluated <code>2 * 3</code> - we would have gotten the same result either way. This is not always the case. Consider the expression <code>(fn x =&gt; 2) (1 div 0)</code>. By eager evaluation, we should evaluate the argument first, which means that this entire expression should raise an exception. Raising an exception thus happens <em>before we even look at the body of the function</em>. For all intents and purposes, the body of the function does not exist to us until we actually enter it - which necessitates that the argument to the function is valuable. It is a black box that is &quot;locked&quot; behind the argument. </p>
<h4><a class="header" href="#footnotes-1" id="footnotes-1">Footnotes</a></h4>
<p>[1]: In other languages, we may instead say <em>call-by-value</em>, which is a separate but closely related concept.</p>
<h1><a class="header" href="#extensional-equivalence" id="extensional-equivalence">Extensional Equivalence</a></h1>
<p>Up to this point, we have been using terms such as &quot;equal&quot; and &quot;equivalent&quot;
rather casually. Such a notion of equality seems to be rather intuitive, at
first glance, not necessarily in need of more exposition. After all, it seems to
be our intuition that if two things are equal, we will &quot;know it when we see it&quot;.
When working in the realm of mathematical expressions, we have some nice
assumptions that lend credence to such a hypothesis - if we are evaluating the
cosine of a number, we don't expect that the cosine function might wait forever
before returning an answer to us. When working with SML code, this becomes a
valid concern, and requires that we have a more particular definition of
equivalence.</p>
<h2><a class="header" href="#motivation-1" id="motivation-1">Motivation</a></h2>
<p>It is at this point that we will try to make the <em>reasons</em> for defining an idea
of extensional equivalence apparent. It has everything to do with the
<em>extensional</em> behavior of our programs - the outputs that it returns given
certain inputs.</p>
<p>Extensional equivalence comes into play when reasoning about the correctness of
programs. A large motive for why we write functional code is linked to an idea
of a <em>formal proof</em> - when writing code without side effects, it is far easier
to reason about the behavior of a program. We would like to be able to provide
some rigorous argument as to why a program is correct. </p>
<p>In imperative settings, it is quite difficult to go about doing so - when
problems of state are added in, a programmer now not only needs to think about
what step a particular program is in at a given moment, but also what the state
of the program is as well. By state, we usually mean the particular arrangement
of mutable data in the program's environment, such as the state of memory
allocation, variable contents, and other transient factors. The possible
configurations of such a state are generally infinite, which makes reasoning
rather more difficult. While one can generally be <em>reasonably</em> sure what the
state of a program should be, it does not always work out that way, as any
programmer who has written a bug can attest. In functional programs, we eschew
side effects for ease in reasoning about what a program truly outputs. Functions
have well-defined results.</p>
<p>Imperative programmers create functional programs. This is, at first, perhaps a
surprising claim, but we will soon delineate what precisely we mean. In making
this claim, we are only considering functions of a certain basic kind - that is,
functions that <em>compute</em>, rather than <em>create</em> or <em>modify</em>. For instance, a
program that generates the Fibonacci numbers, or computes the most efficient
path through a given graph, or encodes some kind of data. We do not consider
programs that, for instance, outputs to a file or prints the contents of the
directory that the program file lives in. In addition, we speak only of programs
that do not return <em>random results</em>, for instance random number generators or
other random selectors. </p>
<p>These programs have the characteristic that they are (in the general case)
<em>deterministic</em>. Given the same inputs, they should return the same output -
regardless of whether the language that they were implemented in is imperative
in nature. So for these varieties of programs (which are very common
computational problems), imperative programs make use of state to achieve a
program that is functional in nature - that is, having no overall visible effect
on the machine's state. Functional programming simply uses functional tools to
achieve the same result, in the end.</p>
<p>This is an important idea to cognize because it forms the basis for our concept
of <em>correctness</em>. We identify a program's correctness by its ability to return
the expected results when given some input. For instance, we know a factorial
function that returns 5 upon being given 3 is no good. Having functional
<em>components</em> helps us easily reason and build up functional <em>results</em> - that is,
an end program that returns the correct results.</p>
<p>As we will see, extensional equivalence will be a powerful tool when reasoning
about the correctness of our code. It lets us prove in a mathematical sense
whether functions are <em>correct</em>, as well as abstract between specific
implementations. We will go further into detail on this later in the chapter.</p>
<h2><a class="header" href="#the-definition" id="the-definition">The Definition</a></h2>
<p>We will declare this definition of extensional equivalence for non-function
expressions first, and then explore the function case later.</p>
<blockquote>
<p><strong>[Extensional Equivalence (Non-Functions)]</strong> We say that two expressions <code>e : t</code> and <code>e' : t</code> for some type <code>t</code> are <em>extensionally equivalent</em> if they
exhibit any of these three behaviors:</p>
<ol>
<li>
<p>Reduce to the same value</p>
</li>
<li>
<p>Loop forever</p>
</li>
<li>
<p>Raise the same exception</p>
</li>
</ol>
<p>We will write <code>e == e'</code> to denote this.</p>
</blockquote>
<p><strong>NOTE:</strong> <code>==</code> is not valid SML code.</p>
<p>As such, clearly expressions such as <code>2 + 2</code> and <code>3 + 1</code> should be extensionally
equivalent, since they reduce to the same value, that being <code>4</code>. It is important
to note that reduction is a <em>stronger</em> relation than extensional equivalence -
if one expression reduces to another, then they must by definition be
extensionally equivalent. However, extensional equivalence does not imply
reduction. For instance, <code>4</code> does not reduce to <code>2 + 2</code>, since clearly <code>4</code> is
already in its most simplified form. This corresponds to our intuition about
traditional mathematical expressions, as we would expect that we could say that
\( -1 \) and \( \cos(\pi) \) are equal, since they have the same value.</p>
<p>With the second point, however, we depart from our normal mathematical
reasoning. It is generally the case that, given a mathematical expression, we
expect to be able to generate a result from it. That result may be undefined,
and it may take some time, but in many cases we don't expect to have to account
for a nonterminating computation. This is not the case in Standard ML. Now, any
given function call may loop forever, which plainly is problematic for
equivalence.</p>
<p>As such, we will add a stipulation that two expressions (of the same type) that
loop forever are extensionally equivalent. Note that even though two expressions
of dissimilar types that loop forever have the same &quot;behavior&quot;, they cannot be
extensionally equivalent by definition, as only expressions of the same type can
be extensionally equivalent. </p>
<p>The third case also arises from our usage of Standard ML, as expressions can
potentially raise exceptions in cases where computation is not feasible. Some
basic kinds of exceptions include <code>Div</code>, <code>Bind</code>, and <code>Match</code>. The precise
mechanism of exceptions is not important, since we will cover that in more
detail later on, but in order to maintain some notion of equivalence, we will
simply require that two same-typed expressions raise the <em>same</em> exception. As
such, expressions like <code>1 div 0</code> and <code>2 div 0</code> are extensionally equivalent,
whereas <code>1 div 0</code> and <code>let val [] = [1] in () end</code> are not.</p>
<p><strong>Note:</strong> It is not important to know specifically what the latter expression in
the last example is doing - just know that it raises the exception <code>Bind</code>.</p>
<p>In writing these definitions we have made a step towards cognizing extensional
equivalence, but in a sense we have taken a step back as well. We have committed
the same mistake by saying extensional equivalence holds when expressions
&quot;reduce to the same value&quot;. We required this more stringent definition of
extensional equivalence specifically because of callously using terms like
&quot;equal&quot; and &quot;equivalent&quot;, and now we've so unthinkingly used the term &quot;same&quot;.
But what does it mean for two values to be the &quot;same&quot;?</p>
<p>For many cases, our intuition will suffice. It is clear to say that <code>2</code> is the
same as <code>2</code>, and <code>2</code> is not the same as <code>&quot;two&quot;</code> (for any self-respecting
programming language, in any case). For one, the types must be the same, and
definitely one integer value should not be &quot;equal&quot; to any other separate integer
value. We might then claim that two values are only &quot;equivalent&quot; if they denote
the same literal value. </p>
<p><strong>NOTE:</strong> The perceptive reader may notice that again, we have used the words
&quot;same&quot; and &quot;separate&quot;. Unfortunately, there is only so far that we can dig this
rabbit hole - at this point, we will have to rely on our intuitions to tell us
that <code>2</code> is indeed the same value as <code>2</code>, and not the same value as <code>3</code> or <code>4</code>,
and call it a day.</p>
<p>This definition will suffice for most types. For functions, however, we will
have to take a different approach.</p>
<blockquote>
<p><strong>[Extensional Equivalence (Functions)]</strong> We say two expressions <code>e : t1 -&gt; t2</code> and <code>e' : t1 -&gt; t2</code> for some types <code>t1</code> and <code>t2</code> are extensionally
equivalent if for all values <code>x : t1</code>, <code>e x</code>\( \cong \)<code>e' x</code>.</p>
</blockquote>
<p>We see that this definition simply takes our previous definition and moves it
one step up. There is an interesting aspect of this rule that depends on a
concept that we have yet to learn, but we will cover that when we get there.
Seen in this way, we can say that two function values that are not the same
literal value may be extensionally equivalent, as their <em>extensional</em> behavior
(that is, their behavior when interacting with other objects) may be the same.</p>
<p>More concretely, let us consider the example of <code>fn x =&gt; x + x</code> and <code>fn x =&gt; 2 * x</code>. Recall from the previous chapter that <code>fn x =&gt; x + x</code> in particular does
<em>not</em> simplify to <code>fn x =&gt; 2 * x</code>, and is in fact itself a value - meaning that
it is in its terminal form, being irreducible to anything other than itself. The
right hand side of any lambda expression is, in a sense, <em>frozen</em> until the
function is given an argument. So then <code>fn x =&gt; x + x</code> and <code>fn x =&gt; 2 * x</code> are
different values, however it is obvious to see that on being given an input they
evaluate to extensionally equivalent values (specifically, the same integer). </p>
<p>As discussed before, our definition of &quot;equivalence&quot; identifies functions with
the values that they output. It should feel intuitively clear - two functions
are exactly equivalent if they return the same output for the same inputs. This
seems to be the definition of computing the &quot;same&quot; function. Notice that we omit
any mention of complexity or <em>how</em> the function goes about computing what it
computes - no matter what path is taken, all that is important is what values
are ultimately outputted. </p>
<h2><a class="header" href="#referential-transparency" id="referential-transparency">Referential Transparency</a></h2>
<p>In this section we will introduce a powerful idea called <em>referential
transparency</em>, which follows as a direct consequence of our definition of
extensional equivalence.</p>
<blockquote>
<p><strong>[Referential Transparency]</strong> Consider an expression <code>e</code> that contains the
expression <code>e1</code> as a sub-expression. For any expression <code>e2</code>\( \cong \)<code>e1</code>, we
can produce the expression <code>e'</code> as the same expression as <code>e</code>, but with each
sub-expression <code>e1</code> replaced with <code>e2</code>, and we will have <code>e</code>\( \cong \)<code>e'</code>. In
words, for an expression <code>e</code> that contains <code>e1</code>, we can swap out <code>e1</code> for an
extensionally equivalent <code>e2</code> to obtain an expression extensionally equivalent
to <code>e</code>.</p>
</blockquote>
<p><strong>NOTE:</strong> The notion of a &quot;sub-expression&quot; here is not very well defined - we
will use our intuition here, similarly with what it means to be the &quot;same
expression&quot;. Gaining an intuition through examples will suffice.</p>
<p>To illustrate this, we might say that the expression <code>4 * (2 + 2)</code> has the
sub-expression <code>2 + 2</code>, and that <code>let val x = f (1 div 0) in x end</code> has <code>(1 div 0)</code> as a sub-expression. In the former case, we can use referential transparency
to say that <code>4 * (2 + 2)</code>\( \cong \)<code>4 * 4</code> and <code>let val x = f (1 div 0) in x end</code>\( \cong \)<code>let val x = f (2 div 0) in x end</code>, by replacing the aforementioned
sub-expressions with <code>4</code> and <code>2 div 0</code>, respectively.</p>
<p>Referential transparency will let us abstract away from the specific makeup of a
certain implementation or expression, instead replacing it as we see fit with
something known to be extensionally equivalent, while still allowing us to
maintain extensional equivalence. This comes in handy when proving that an
implementation of a particular function is correct, as we can simply prove that
it is extensionally equivalent to an existing, simpler implementation that is
already known to be correct. This has consequences for simplifying and
optimizing implementations.</p>
<p>Later on, we will explore specifically how we may go about proving extensional
equivalence. This will primarily take the form of mathematical or structural
induction.</p>
<h2><a class="header" href="#stepping-with-valuable-expressions" id="stepping-with-valuable-expressions">Stepping with Valuable Expressions</a></h2>
<p>Recall from the previous article that SML uses eager evaluation. In other words,
the parameters of a function are evaluated before stepping into the function.</p>
<p>When proving extensional equivalence theorems about SML code, though, we often
end up in a situation where we want to step into a function, but the function is
being applied to an expression that isn't a value.</p>
<p>We will look at an example of this situation, involving the functions <code>@</code>
(append) and <code>rev</code>. The definition of <code>@</code> is as follows:</p>
<pre><code class="language-sml">fun [] @ L = L
  | (x::xs) @ L = x::(xs@L)
</code></pre>
<p>Now, suppose we want to show the following theorem:</p>
<p><code>(x::xs) @ (rev A)</code> \( \cong \) <code>x::(xs @ (rev A))</code></p>
<p>where <code>x : int</code>, <code>xs : int list</code>, and <code>A : int list</code> are all values. First, make
sure this &quot;feels right&quot; -- the left side of our theorem matches the second
clause of <code>@</code> with <code>rev A</code> bound to <code>L</code>.</p>
<p>However, notice that <code>rev A</code> is not a value. Since SML is eager, we cannot step
into the function <code>@</code> until we evaluate the expression <code>rev A</code>. In other words,</p>
<p>\[ <code>(x::xs) @ (rev A)</code> \not\Longrightarrow <code>x::(xs @ (rev A))</code> \]</p>
<p>So, we're stuck! D:</p>
<p>... or are we?</p>
<p>Let's assume that <code>rev A</code> is valuable, i.e. it evaluates to a value, and let's
give that value a name-- say, <code>v : int list</code>: \[ <code>rev A</code> \Longrightarrow <code>v</code> \]
With this value in hand, we can do what we wanted to do!</p>
<p>\[ <code>(x::xs) @ (rev A)</code> \Longrightarrow <code>(x::xs) @ v</code> \Longrightarrow <code>x::(xs @ v)</code>
\]</p>
<p>Notice that this complies with SML's eager evaluation, since we are fully
evaluating the parameters of <code>@</code> before stepping into the function.</p>
<p>And here's the kicker: we can also use <code>v</code> to evaluate the right hand side of
our theorem!</p>
<p>\[ <code>x::(xs @ (rev A))</code> \Longrightarrow <code>x::(xs @ v)</code>
\]</p>
<p>Again, this complies with SML's eager evaluation-- in this case, we never even
step into the definition of <code>@</code>. But, we've actually proven our theorem! We
showed that the LHS and the RHS both evaluate to the same expression, so by rule
1 of the definition of \( \cong \), the LHS and RHS must be extensionally
equivalent. We are done!</p>
<p>In this example, we got around SML's eager evaluation by assuming that our
parameter <code>rev A</code> is valuable, and as it turns out, this concept holds in the
general case. If we know the parameter of a function is <em>valuable</em>, then we can
step into the function <em>without</em> first evaluating that parameter. This
principle, which we will call (for lack of a better term) &quot;stepping with
valuable expressions,&quot; is one reason why valuable expressions are so important.</p>
<blockquote>
<p><strong>[Caution!]</strong> When stepping with <em>values</em>, we can use the reduction relation
\( \Longrightarrow \). When stepping with <em>valuable expressions</em>, this is not
always true (it certainly is not true in the example above). Stepping with
valuable expressions only preserves extensional equivalence \( \cong \).</p>
</blockquote>
<h2><a class="header" href="#totality" id="totality">Totality</a></h2>
<p>As stated previously, frequently we will write proofs demonstrating the
extensional equivalence of two expressions. In order to do so, we often will
have to expand definitions, stepping through function bodies and applying
lemmas. In doing so, we will frequently need to do a <em>totality citation</em>, to
justify that making such steps is truly valid. While the name may seem
unfamiliar, it ultimately belies a concept that you already know - valuability.</p>
<blockquote>
<p><strong>[Total]</strong> We say that a function <code>f : t1 -&gt; t2</code> for some types <code>t1</code> and <code>t2</code>
is <em>total</em> if for all valuable expressions <code>x : t1</code>, <code>f x</code> is valuable. In
other words, for all valuable inputs to <code>f</code>, we get a valuable output.</p>
</blockquote>
<p>Examples of total functions include <code>fn x =&gt; x + 1</code>, <code>fn x =&gt; &quot;foo&quot;</code>, and the
length function for lists. Notably, however, the factorial function is <em>not</em>
total:</p>
<pre><code class="language-sml">fun fact (0 : int) : int = 1
  | fact (n : int) : int = n * fact (n - 1)
</code></pre>
<p>This function is not total because, while <code>fact n</code> is valuable for all
non-negative <code>n</code>, <code>fact n</code> for a negative <code>n</code> loops forever, as it decrements
infinitely, never finding a base case. Thus, <code>fact</code> is not total. Sometimes if a
function is valuable only on certain inputs, then we will say that a function is
&quot;total over&quot; some domain, even if it is not total in general. We may say that
<code>fact</code> is thus total over the non-negative integers, though this is not a common
practice.</p>
<p>We will now digress slightly to consider an example. What can we say of the
behavior of a function <code>fn x =&gt; 15150</code>? Well, we can characterize its behavior
in words - it returns <code>15150</code> on all inputs. We must be careful when linking our
intuition regarding this function to the actual evaluational semantics of SML -
however. Consider the expression <code>(fn x =&gt; 15150) (1 div 0)</code>. If we went along
with our previous conclusion, we might say that this is <code>15150</code>. This
contradicts what we learned in the previous section, however. Since SML is
eagerly evaluated, this expression should raise an exception and never reach the
function body at all. </p>
<p>This is an easy mistake to catch when considering an explicit, definite input
like <code>1 div 0</code>, but oftentimes we will be considering inputs that might be
&quot;unspecified&quot; in some sense. They may be the result of computations that we are
not fully convinced of, which could return an expression with any kind of
behavior. Suppose we were wondering the behavior of <code>(fn x =&gt; 15150) (f y)</code>, for
some function <code>f</code> and value <code>y</code>. Now, we aren't sure at all if this expression
does what we think it might do, which is return <code>15150</code> - that depends entirely
on the definition of <code>f</code> and the value of <code>y</code>.</p>
<p>This is where totality comes in. Totality is oftentimes like a sledgehammer,
being far more brutish and exhaustive than its use cases necessitate. It is
undeniably useful, however. With totality, we do not have to reason about the
behavior of a function on any specific inputs - we can just handwave them all
and say that no matter what, it must return a valuable output, which is what we
really care about. If we revisit the expression <code>(fn x =&gt; 15150) (f y)</code> with the
totality of <code>f</code> in hand, now reasoning about it is very simple. We know that <code>y</code>
is a value, and that <code>f</code> is total, so by definition <code>f y</code> is valuable. This
means that, regardless of what value <code>f y</code> <em>actually</em> evaluates to, we can step
into the body of <code>(fn x =&gt; 15150)</code>, and thus conclude that the expression
reduces to <code>15150</code>.</p>
<p>More generally, suppose we have the following definition:</p>
<pre><code class="language-sml">fun f (x : int) : int = e
</code></pre>
<p>where <code>e</code> denotes some expression that we will leave unspecified for the moment.
Thus, <code>f</code> is a function that takes in some input of type <code>int</code>, and produces a
val binding to bind it to the identifier <code>x</code>, and then evaluates the expression
of <code>e</code> in the scope of that binding. Note that such a binding is truly a <em>val</em>
binding - since we have eager evaluation, the input must first be evaluated to a
value, and then bound to the identifier <code>x</code>.</p>
<p>Then, consider the expression <code>f (g y)</code>, where <code>g</code> is some other function and
<code>y</code> is some value. Oftentimes, we would like to just step through the definition
of <code>f</code> in some proof, and say that <code>f (g y)</code> reduces to the expression <code>e</code> in
the scope of the binding <code>[(g y)/x]</code> (recall that this is our notation for
&quot;binding the value of <code>g y </code> to the identifier <code>x</code>). This is not always possible
in general, however. Recall that a well-typed expression either reduces to a
value, loops forever, or raises an exception. If <code>g y</code> were to loop forever,
would we be able to enter the function body of <code>f</code>, and evaluate <code>e</code>? </p>
<p>Of course we would not - this is just another consequence of eager evaluation.
Evaluation of <code>f (g y)</code> would get &quot;stopped at the door&quot;, so to speak. We would
not be able to enter <code>f</code> because <code>g y</code> does not reduce to a value. Since the
input to <code>g</code> is arbitrary, in this case, to be able to claim that <code>f (g y)</code>
enters the function body of <code>f</code> requires that we know the totality of <code>g</code>. We
thus use totality as a <em>tool</em> to get at what is really important - the
valuability of the arguments to <code>f</code>, which in this case is <code>g y</code>. As such, while
we may refer to such citations as &quot;totality citations&quot;, and name this idea of
totality, do not forget that this is all just a consequence of eager evaluation.
We are really looking for <em>valuability of arguments</em>.</p>
<h1><a class="header" href="#pattern-matching" id="pattern-matching">Pattern Matching</a></h1>
<p>Patterns take on many appearances, such as:</p>
<ul>
<li>Constants: <code>150</code></li>
<li>Variables: <code>x</code></li>
<li>Wildcard: <code>_</code></li>
<li>Tuples: <code>(true, _)</code></li>
<li>Constructors (which may contain other patterns):
<ul>
<li>Lists: <code>x::xs</code></li>
<li>Other datatypes: <code>Node(L,x,R)</code></li>
</ul>
</li>
</ul>
<p>Patterns can be matched against values to form bindings. In the following example, <code>1</code> gets bound to <code>x</code>, and <code>2</code> gets bound to <code>y</code>.</p>
<p><code>val (x,y) = (1,2)</code></p>
<p>Pattern matching may fail. For example, the following raises exception <code>Bind</code>.</p>
<p><code>val 10 = 9</code></p>
<p>Besides <code>val</code> declarations, pattern matching is also used in function declarations, lambda expressions, and case expressions.</p>
<h2><a class="header" href="#function-declarations" id="function-declarations">Function declarations:</a></h2>
<pre><code>fun fact 0 = 1
  | fact n = n * fact(n-1)
</code></pre>
<p>The function <code>fact</code> is given an <code>int</code> as input. If the input successfully matches the pattern <code>0</code>, then the function returns <code>1</code>. Otherwise, the input is matched with the pattern <code>n</code>, binding the input to <code>n</code>. For example, if we evaluate <code>fact 5</code>, then <code>5</code> is bound to <code>n</code>, so the expression becomes <code>5 * fact(4)</code>. </p>
<p>Each clause of the function declaration tells <code>fact</code> what it should do, depending on the input. The bar, <code>|</code>, acts as a separator between the two clauses. </p>
<p>Note that it's important for your patterns to be <em>exhaustive</em>. The above function is fine, because all values of type <code>int</code> can match with either <code>0</code> or <code>n</code>. However, suppose we had the following function:</p>
<pre><code>fun fiction 1 = 1
  | fiction 2 = 2
  | fiction 3 = 6
</code></pre>
<p>There are many inputs which do not match with either <code>1</code>, <code>2</code>, or <code>3</code>. For example, <code>fiction 4</code> would raise exception <code>Match</code>.</p>
<h2><a class="header" href="#lambda-expressions" id="lambda-expressions">Lambda expressions:</a></h2>
<p><code>(fn [] =&gt; false | x::xs =&gt; true) [1,2,3]</code></p>
<p>The lambda expression is similar to a function; as it turns an input into an output. In the example above, <code>[1,2,3]</code> is the input. It doesn't match with <code>[]</code>, but it does match with <code>x::xs</code>. Namely, <code>1</code> gets bound to <code>x</code>, and the list <code>[2,3]</code> gets bound to <code>xs</code>. As a result of this successful pattern matching, the lambda expression returns <code>true</code>. </p>
<p>You should still make sure your patterns are exhaustive. For example, the following codeblock raises exception <code>Match</code>:</p>
<p><code>(fn [] =&gt; false) [1,2,3]</code></p>
<h2><a class="header" href="#case-expressions" id="case-expressions">Case expressions:</a></h2>
<pre><code>fun fact x =
    case x of
        0 =&gt; 1
      | n =&gt; n * fact (n-1)
</code></pre>
<p>First, note that this codeblock does the same thing as the example for function declarations. However, it uses an extra <code>case</code> expression.</p>
<p>Let's consider what happens when <code>fact</code> is given an input, like <code>5</code>. First, <code>5</code> gets bound to <code>x</code>. Then, the <code>case</code> expression tries to match <code>5</code> to a pattern. In this scenario, <code>5</code> successfully pattern matches with <code>n</code>, so <code>5</code> gets bound to <code>n</code>. Therefore, <code>fact 5</code> evaluates to <code>5 * fact(4)</code>. </p>
<p>As usual, the patterns in <code>case</code> expressions should be exhaustive.</p>
<h1><a class="header" href="#recursion-and-induction" id="recursion-and-induction">Recursion and Induction</a></h1>
<p># Thinking About Recursion Inductively</p>
<p>There's a strong association between mathematical induction and recursion, especially in SML. Often times, we'll be able to use similar vocabularies when describing SML problems and mathematical induction. In particular, we're going to be use the words <strong>base case, induction hypothesis, and induction step</strong> to describe both types of problems.</p>
<h2><a class="header" href="#inductive-intuition" id="inductive-intuition">Inductive Intuition</a></h2>
<p>Approaching induction proofs can fall along the following line of logic:</p>
<ol>
<li>Solve the <strong>base cases</strong>.</li>
<li>Define the <strong>inductive hypothesis</strong>.</li>
<li>Assume the correctness of the <strong>inductive hypothesis</strong> to show the correctness of the <strong>inductive step</strong>.</li>
</ol>
<p>We can similarly apply this line of logic to solving problems with SML functions! Let's take a look at a common recursive problem. <code>treeSum</code> takes an int tree and returns the sum of all the integers in that tree. By the end of this, we'll be able to implement recursive functions with the following inductive logic:</p>
<pre><code class="language-sml">fun treeSum (Empty : int tree) : int = 0
  | treeSum (Node(L,x,R)) = treeSum(L) + treeSum(R) + x
</code></pre>
<blockquote>
<p>The <strong>base case</strong> for <code>treeSum</code> is that an <code>Empty</code> tree has a sum of 0. Let's define the <strong>inductive hypothesis</strong> to be that for some tree <code>T</code>, that <code>treeSum</code> is correct for its left subtree and right subtree. Define my <strong>inductive step</strong> to be for a tree <code>T = Node(L,x,R)</code>. By the definition of trees, I know that all integers in <code>T</code> are represented by the integers in <code>L</code>, <code>R</code>, and the integer <code>x</code>. If I sum all of these, I will get <code>treeSum(T)</code>. By assuming the <strong>IH</strong>, I can say that <code>treeSum L</code> and <code>treeSum R</code> are correct. Therefore, by math, I will say that <code>treeSum T = (treeSum L) + (treeSum R) + x</code> is correct by the above reasoning. As such, I've shown my <strong>IS</strong> to be correct, and thus the theorem that <code>treeSum T</code> is correct for all <code>T : int tree</code>.</p>
</blockquote>
<h2><a class="header" href="#an-exploration-of-tree-sums" id="an-exploration-of-tree-sums">An Exploration of Tree Sums</a></h2>
<p>Let's define <code>treeSum</code>. This function should take in an <code>int tree</code> and return the sum of all the integers in that tree.</p>
<pre><code class="language-sml">datatype int tree = Empty | Node of int tree * int * int

fun treeSum (T : int tree) : int = ...
</code></pre>
<p>Note that in SML, the <code>tree</code> datatype is recursively defined. This is a good hint that we should be using recursive/inductive strategies to approach this problem. Consider the proof of the following theorem:</p>
<blockquote>
<p><strong>Theorem:</strong> For all <code>T : int tree</code>, <code>treeSum T</code> is correct.</p>
</blockquote>
<p>Let's not worry about formalizing this proof too much so that we can focus on the <strong>inductive intuition</strong> of it. If we were to prove this using induction, we'll need a <strong>(1) base case, (2) induction hypothesis, and (3) induction step.</strong></p>
<h3><a class="header" href="#1-solving-for-the-base-cases" id="1-solving-for-the-base-cases">1. Solving for the Base Cases</a></h3>
<p>Let's first think about proving the base case: <code>T = Empty</code>. What does it mean for <code>treeSum Empty</code> to be correct? Well, an <code>Empty</code> tree does not have any nodes, and if there are no nodes, there are no <code>int</code> values. The sum of nothing is 0. Let's write that in a proof-like manner:</p>
<blockquote>
<p><strong>Base Case:</strong> <code>T = Empty</code></p>
<ul>
<li><code>treeSum(Empty) ==&gt; 0</code> because an <code>Empty</code> int tree does not have an int value.</li>
</ul>
</blockquote>
<p>That wasn't so bad! If we have an empty node, we can't have a value there, and so the sum is 0. Before we move on to solving the recursive step, let's tie in this idea of how recursion and induction are related. In our proof, we say that <code>treeSum Empty</code> is correct when it evaluates to 0. Let's use this as an answer to how to define the base case of our function:</p>
<pre><code class="language-sml">fun treeSum (Empty : int tree): int = 0
</code></pre>
<p>Nice job! We've leveraged inductive reasoning to help us define the base case for our recursive problem. Let's move on to something a little harder and may be less obvious than what we've done here.</p>
<h3><a class="header" href="#2-define-the-inductive-hypothesis" id="2-define-the-inductive-hypothesis">2. Define the Inductive Hypothesis</a></h3>
<p>The next step in our proof is to define the inductive hypothesis. Here, we'll assume the correctness of a smaller part, then use that to prove the correctness of a bigger part. More specifically, we'll be using some ideas of <a href="https://smlhelp.github.io/#todolinktostructuralinductionsection">structural induction</a> for this problem. Let's elaborate more on that:</p>
<blockquote>
<p><strong>Induction Hypothesis:</strong> Assume for all <code>L : int tree</code> and <code>R : int tree</code> that <code>treeSum L</code> is correct and <code>treeSum R</code> is correct.</p>
</blockquote>
<p>Because we've shown our base case to be true, let's assume tha for the recursive structures (the left subtree <code>L</code> and the right subtree <code>R</code>), <code>treeSum</code> is correct. Just like how in induction we can use these nuggets of information to help us prove our <strong>inductive step</strong>, we can do the same to help us solve the SML function.</p>
<h3><a class="header" href="#3-assume-the-inductive-hypothesis-to-show-the-inductive-step" id="3-assume-the-inductive-hypothesis-to-show-the-inductive-step">3. Assume the Inductive Hypothesis to Show the Inductive Step.</a></h3>
<p>What nuggets of information do we know from the previous step, and how can we use that to help us with inductive step? We assume that both <code>treeSum L</code> and <code>treeSum R</code> are correct by the <strong>inductive hypothesis (IH)</strong>. Since they are correct, their outputs represent the sum of all the integers in them. For <code>treeSum L</code> is the sum of all integers in the int tree <code>L</code> and for <code>treeSum R</code> is the sum of all integers in the int tree <code>R</code>.</p>
<p>We also know that since <code>L</code> and <code>R</code> are the left and right subtrees of <code>T</code>, by definition, they represent all nodes of <code>T</code> (except the root node). Then, to get sum of <code>T</code>, we just need the sum of <code>L</code>, <code>R</code>, and the value of the root node! Let's proof-ify this line of thought a bit more:</p>
<blockquote>
<p><strong>Inductive Step:</strong> <code>T = Node(L,x,R)</code></p>
<ul>
<li><code>treeSum L</code> is correct by <strong>IH</strong></li>
<li><code>treeSum R</code> is correct by <strong>IH</strong></li>
<li>&quot;All integers in <code>T</code>&quot; are represented by &quot;all integers in <code>L</code>&quot;, &quot;all integers in <code>R</code>&quot;, and <code>x</code> by definition of trees.</li>
<li>The sum of &quot;all integers in <code>T</code>&quot; is the sum of &quot;all integers in <code>L</code>, &quot;all integers in <code>R</code>&quot;, and the integer <code>x</code>.</li>
<li><code>treeSum T = (treeSum L) + (treeSum R) + x</code> by definition of <code>treeSum</code>.</li>
<li><code>(treeSum L) + (treeSum R) + x</code> is correct by math and above logic.</li>
<li><code>treeSum T</code> is correct by substitution.</li>
</ul>
</blockquote>
<p>Using the logic needed to complete the proof, we were able to arrive at how to implement our function! Let's translate the above logic into SML:</p>
<pre><code class="language-sml">fun treeSum (Empty : int tree) : int = 0
  | treeSum (Node(L,x,R)) = (treeSum L) + (treeSum R) + x
</code></pre>
<h2><a class="header" href="#qed" id="qed">QED</a></h2>
<p>And like that, we're able to leverage mathematical induction to help us find the solution to part of an SML function. For some, this intuition is obvious. But for others, it isn't! A deep spiral of pure math and proving every single aspect of your code isn't usually needed. <strong>BUT</strong>, it will definitely be helpful to adopt this style of thinking when approaching more difficult and advanced recursion problems. Whenever you're trying to implement a recursive function in SML, remember to think inductively!</p>
<ol>
<li>Solve the <strong>base cases</strong>.</li>
<li>Define the <strong>inductive hypothesis</strong>.</li>
<li>Assume the correctness of the <strong>inductive hypothesis</strong> to show the correctness of the <strong>inductive step</strong>.</li>
</ol>
<h1><a class="header" href="#tail-recursion" id="tail-recursion">Tail Recursion</a></h1>
<h1><a class="header" href="#asymptotic-analysis" id="asymptotic-analysis">Asymptotic Analysis</a></h1>
<p>We have now dedicated a significant amount of discussion towards how to reason about the correctness of programs. Correctness, however, is not the end-all-be-all. In many cases, we would like to be able to think about the <em>complexity</em> of our programs - that is, the amount of resources that it takes to run it on certain inputs. Such resource concerns may include time, space, and energy usage. For the purposes of this book, our principal resource of interest will be <em>time</em>.</p>
<h2><a class="header" href="#the-reality" id="the-reality">The Reality</a></h2>
<p>It is, however, hopefully clear that this question is rather ill-founded. For one thing, hardware limitations mean that running the same program on different machines may yield differing results, based on the performance ability of individual machines. Indeed, even running the same program on the same machine may yield different results, based on the the computer's current workload. We want a metric that is somehow agnostic to these implementation details, that can give us an idea of how efficient an algorithm is. </p>
<p>Additionally, we are usually not just interested in a program's runtime based on a single input, but its behavior across a wide range of inputs. Additionally, the possibility of infinitely many inputs makes empirical methods like taking an average rather infeasible. Generally, programs also tend to have &quot;worse&quot; inputs than others. It is not necessarily fair to compare the time it takes to compute the millionth Fibbonaci number with the time it takes to compute the second. We will have to do better.</p>
<h2><a class="header" href="#the-solution" id="the-solution">The Solution</a></h2>
<p>We will generally turn to <em>asymptotic analysis</em> to solve these issues. It provides a nice mathematical definition that conveniently takes care of many of the points previously mentioned.</p>
<blockquote>
<p><strong>[Big-O]</strong> We say that a function \( f : \mathbb{R}^+ \rightarrow \mathbb{R}^+ \) is in big-O of another function \( g : \mathbb{R}^+ \rightarrow \mathbb{R}^+ \) (write \( f(n) = O(g(n) \) or \( f(n) \in O(g(n)) \)) if there exist constants \( c, n_0 &gt; 0 \) such that for all \( n \geq n_0 \), \( f(n) \leq cg(n) \). In words, \( f(n) = O(g(n)) \) if there exists a point beyond which \( f(n) \) can be upper bounded by \( g(n) \), amplified by some constant factor.</p>
</blockquote>
<p>In intuitive terms, we can think of a function \( f \) as being in big-O of another function \( g \) if it is &quot;less than or equal to&quot; that function, in terms of the complexity class that it belongs to. For instance, \( 2x \) is \( O(x^2) \), and also \( O(x) \), the former being because a quadratic function grows faster than a linear function by a factor of \( x \), and the latter being because we effectively do not care about constant factors. Note that for that example, we can choose \( c = 2 \), which makes \( f(n) = cg(n) = 2x \), which clearly makes \( f(n) \leq cg(n) \) true.</p>
<p>Asymptotic analysis allows us a convenient notion of what the runtime of a function really is in terms of the <em>size of the input</em>. We will usually define what metric this takes, but common measures include the length of a list, the number of nodes in a tree, or something similar. If we let \( T(n) \) denote the function that maps input sizes to worst-case &quot;runtimes&quot; (that is, \( T(x) \) is the maximum number of steps it takes to run on an input of size \( x \)), then we are usually interested in <em>upper bounding</em> \( T(n) \) - that is, determining what complexity class it falls into. Note, however, that we are simply finding upper bounds - the idea is that this \( T(n) \) function cannot be determined exactly, but its <em>approximate asymptotic behavior</em> can be upper bounded by a different, more defined function. We also care about achieving a <em>tight</em> upper bound - one that is not unnecessarily large. For instance, we could say that <em>many</em> functions are in \( O(2^{2^n}) \) - but this is not particularly useful information. You must be careful to perform analyses without being <em>too</em> liberal.</p>
<p><strong>NOTE:</strong> By &quot;number of steps&quot;, we usually mean some idealized notion of some &quot;step of computation&quot; that an algorithm takes, such as the number of comparisons that it takes to run a quicksort algorithm, or the number of times that we cons an element on or off a list. This lets us abstract away from how long it <em>actually</em> takes a computation to run, ignoring the physical machines used. We only care about the high-level &quot;steps&quot; that an algorithm takes, which is the same regardless of platform.</p>
<p>In a world with an incredible amount of data being processed and transmitted in our daily lives, asymptotic analysis forms a nice metric for the efficiency of algorithms. Most of the specific content that has been discussed so far is beyond the scope of this book, but it is good to have an intuitive understanding of asymptotic analysis nonetheless. </p>
<h2><a class="header" href="#asymptotic-analysis-at-a-glance" id="asymptotic-analysis-at-a-glance">Asymptotic Analysis at a Glance</a></h2>
<p>Oftentimes, one will have to &quot;eyeball&quot; the complexity of their function or program. This really just amounts to knowing what operations that it executes, and how many times they are executed.</p>
<p>For instance, consider the following function:</p>
<pre><code class="language-sml">fun foo (0 : int) : int = 0
  | foo (n : int) : int = n + foo (n - 1)
</code></pre>
<p>Clearly, this function simply computes the sum of the first \( n \) nonzero numbers upon being given \( n \) as an input. What it does is not important, but if we were to try and quantify the complexity of <code>foo</code>, we might say that it is \( O(n) \) in \( n \), the value of the number given as input. This is because we can consider arithmetic operations to be constant-time (that is, running in \( O(1) \)), and we know that the function should recurse \( n \) times. </p>
<p>But now let us consider how long it might take to run the following code fragment:</p>
<pre><code class="language-sml">fun bar (0 : int) : int = 0
  | bar (n : int) : int = (foo n) + bar (n - 1)
</code></pre>
<p>Now, instead of adding <code>n</code>, each computation in the recursive step instead adds <code>foo i</code>, invoking the previous function. </p>
<p>This becomes slightly harder to eyeball. We can eyeball this as upper boundable by \( O(n^2 \), though we would desire some more justification than just what it &quot;seems to be.&quot; We will need to turn to more sophisticated methods to analyze this more formally, which we will cover in the next chapter. The general idea of estimating complexity, however, is simply to look at programs in terms of their components - how many times instructions run, and what the cost of each instruction's individual cost is. This becomes a very powerful method of reasoning that we will explore more later when we discuss sequences, though we will introduce a way to do so in a slightly more rigorous manner.</p>
<style>
.aligncenter {
    text-align: center;
}
</style>
<h1><a class="header" href="#work-and-span" id="work-and-span">Work and Span</a></h1>
<p>We will now turn towards a more robust notion of <em>work</em> and <em>span</em> that let us
analyze our conception of asymptotic runtime more effectively. It is still
dependent on asymptotic analysis, but merely involves being more involved with
how we go about generating the asymptotic bound for a function from the code
itself. Additionally, we will not only analyze the approximate <em>number of steps</em>
of the program (which corresponds to the <em>runtime</em> of the program, given
sequential execution), but also the approximate <em>longest chain of dependencies</em>
that exists in the program, assuming that computations can be run in parallel.
We will elaborate more on this idea in this chapter.</p>
<h2><a class="header" href="#parallel-computing" id="parallel-computing">Parallel Computing</a></h2>
<p>It is intuitive to view things occurring sequentially. Whether it is reading a
tutorial, writing a list of instructions, or making a plan for the future,
sequential actions are very easy to think about. Even programs are written in a
stepwise manner, with computations happening one after the other in a prescribed
way. It seems to be in our nature to impose some kind of order on a list of
actions.</p>
<p>Despite that, however, sequential evaluation is not always the most <em>efficient</em>.
Sequential evaluation introduces <em>dependencies</em> where other subtasks cannot be
started until we have finished the current subtask, which has the effect of
potentially inducing wait times where none exist. For instance, if your plan is
to do the laundry and your homework, it might not be the most time-efficient to
wait until the washer is done before get started on your work. There is no
dependency between laundry and homework - there is no logical reason why you
should have to wait for one before the other, so you could do them both at the
<em>same time</em>, or in <em>parallel</em>.</p>
<p>Parallel computing is a principle that is becoming more and more important as
time goes on. Computers now more frequently have multiple cores in their
processors, which means that tasks can be subdivided and assigned out to
independent acting agents. </p>
<p>The benefits of doing so are clear. Suppose that we are stacking a shelf with
merchandise. If the shelf is tall, this may take us a while - roughly linear in
the height of the shelf, we can imagine (supposing we have an infinite stock of
items, and that climbing a ladder somehow isn't a factor). If we had a person to
dedicate to each shelf, however, then we could stock the shelves in &quot;constant&quot;
time - independent of the number of shelves that there actually are. This will
be a driving idea behind how we look at parallelism.</p>
<p>While we will not delve into the implementation details of parallel computing
(which is more apt for a systems perspective), we will perform basic analysis of
asymptotic complexity based on that premise. These take the form of <em>work</em> and
<em>span</em>, fundamental ideas that will drive the next section.</p>
<h2><a class="header" href="#theory" id="theory">Theory</a></h2>
<p>First, let us consider what we will term a <em>task dependency graph</em>. This is not
so important of a concept to memorize, but it will help in conceptualizing work
and span. A task dependency graph is a directed acyclic graph (that is, a graph
whose edges are one-way, and there exist no loops) that represents the
dependencies when trying to perform a set of tasks. Each node is a task,
labelled with the time that it takes to execute it (which is a singular unit,
unable to be reduced otherwise), as well as edges that represent the
dependencies in the graph. Any task cannot be started until all of the tasks
that have edges directed towards it are finished - that is, all of a task's
inbound edges denote its prerequisites.</p>
<p>With this knowledge, we will be able to define what we mean by work and span.</p>
<blockquote>
<p><strong>[Work]</strong> The <em>work</em> of a computation denotes the number of steps it takes to
run, assuming access to only a single processor. Work thus represents the
worst-case sequential evaluation time, and can be upper bounded with
asymptotic analysis.</p>
</blockquote>
<blockquote>
<p><strong>[Span]</strong> The <em>span</em> of a computation denotes the number of steps that it
takes to run, assuming access to infinitely many processors that allow us to
run tasks in parallel. Span thus represents the worst-case parallel evaluation
time, and can be upper bounded with asymptotic analysis.</p>
</blockquote>
<p>What we find is that work directly corresponds to our previous intuition of the
complexity of a computation, since our previous analyses have always been
sequential. Span, however, is not quite as easy to eyeball. Now, we are really
looking for the <em>longest chain of dependencies</em>, that is, the longest sequence
of tasks that <em>must</em> be run sequentially, since everything else can be run
concurrently. Infinitely many processors, while obviously unrealistic, helps to
simplify our analysis, and provides us a &quot;target&quot; for the efficiency of a
<em>fully</em> parallel algorithm.</p>
<p>We illustrate these concepts with the following graph.</p>
<figure class="aligncenter">
    <img src="concepts/../assets/graphTransCropped.png" alt="Process Graph" width="1000"/>
    <figcaption><b>Fig 1.</b> Task dependency graph illustrating dependencies between tasks and task durations</figcaption>
</figure>
<p>So in this example, the work of our graph would be \( 1+3+6+2+5+9+3+3+10 = 42 \),
since with a single processor, the dependencies don't really matter to us. We
have no choice but to complete every task, and the precise order doesn't matter.
That isn't to say that we can execute the tasks in any order, that plainly isn't
true - we simply mean that there is no order that can change what our runtime
is.</p>
<p>On the other hand, for span we must consider the length of the <em>longest path</em>.
The span of this graph would thus be \( 1 + 3 + 6 + 9 + 10 = 29 \), since that is
the longest path. Even being able to execute everything else in a parallel way,
we cannot avoid the fact that these nodes must follow one after the other. This
path is thus the limiting factor in our runtime - ultimately it constrains the
amount of time that we expend.</p>
<p>Task dependency graphs are a concept that we discuss purely for theoretically
being able to understand the idea of work and span. We will look at examples in
terms of actual SML code in the next section, which will be primarily where we
do our work/span analysis.</p>
<h2><a class="header" href="#workspan-analysis-of-code" id="workspan-analysis-of-code">Work/Span Analysis of Code</a></h2>
<p>The previous example was rather contrived. For one thing, it is <em>prespecified</em> -
we already knew all of the tasks that there were, along with its dependencies
and task times. As such, we could compute a simple, numerical answer. This will
likely not be the case. We are interested in work/span analysis of <em>algorithms</em>,
which will yield us <em>another</em> function - one describing the runtime complexity
of the algorithm as a function of some notion of input size.</p>
<p>For recursive functions, work/span analysis is very easy to do. We characterize
it in terms of <em>recurrence relations</em>, which are themselves recursive functions
describing the work or span of some code. Then, we simply solve for the closed
form of the recurrence relation and estimate a Big-O bound to arrive at our
desired complexity.</p>
<p>Consider the following example:</p>
<pre><code class="language-sml">fun length ([] : int list) : int = 0
  | length (x::xs : int list) : int = 1 + length xs
</code></pre>
<p>The first step to determining the work and span of such a function is to write a
recurrence relation. These steps are explicit - the code should determine the
recurrence relation, and the recurrence relation should determine the Big-O
bound. We will first analyze this function's work complexity, then move on to
span.</p>
<p>First, we should fix some notion of input size. This will differ based on what
our recurrence is recursing on, but in this example it seems to be the size of
the input list. Note that this follows directly from the code - if this were the
factorial function, we may say that the recurrence is in terms of the value of
the input, and as we will later see, if the input was a tree, we may write the
recurrence in terms of the number of nodes in the tree.</p>
<p>So we can write the following recurrence for work. We will explain soon what
exactly it means, and how to arrive at it:</p>
<center> \( W_{length}(n) = c_0 + W_{length}(n-1) \) </center>
<center> \( W_{length}(0) = c_1 \) </center>
<p>This recurrence is made of two parts - the recursive case and the base case. The
first equation for \( W_{length}(n) \) simply denotes what the work for an input
size of \( n \) should be - defined recursively. The second equation for
\( W_{length}(0) \) defines what the work for an input size of \( 0 \) should be.
This directly corresponds to our code, which has two clauses for a list of
length \( 0 \) (that being <code>[]</code>), and for the general case. This is an important
observation to make, that the recurrence follows directly from the code.</p>
<p>The recursive case says that, for an input of size \( n \), the work done is \( c_0 + W_{length}(n-1) \). 
Here, \( c_0 \) denotes <em>some</em> constant. This is supposed to correspond to the recursive case of 
the function, and if we look at it, we have a recursive call <code>length xs</code>, as well as some 
other work of adding one. Adding one, being an arithmetic operation, is a constant-time 
process, meaning that it takes a non-zero constant amount of time. This is what \( c_0 \) is supposed to
represent - the constant amount of non-recursive work that must be done, after
the recursive call has finished. It is not important what \( c_0 \) is, just that
it is some unspecified amount of work that is not a function of \( n \).</p>
<p>Conversely, \( W_{length}(n-1) \) represents exactly the amount of work done by
the recursive call, since it is literally defined to be the amount of work done
by an input of size \( n-1 \), which is exactly what happens when we call <code>length xs</code>, where <code>xs</code> has length \( n-1 \).</p>
<p><strong>NOTE:</strong> Even if we did not have the addition operation, we would still have
\( c_0 \). This is because merely entering the function and figuring out which
case to execute takes some non-zero amount of work - it is impossible to run the
recursive call perfectly with no other time expense. As such, we would see
exactly the same recurrence even if the recursive case was <code>length (x::xs : int list) : int = length xs</code> (which would also be a very bad length function).</p>
<p>For the base case, we have that \( W_{length}(0) = c_1 \), since in the base case
we just return 0. This has a constant amount of work associated with it, as
argued previously, so we use the constant \( c_1 \) to denote that, since the
amount of work is likely not the same constant as that in the recursive case,
when adding 1. </p>
<p>So this is how we arrive at the work recurrence for <code>length</code>. We will now turn
to the span recurrence, which we obtain as:</p>
<center> \( S_{length}(n) = c_0 + S_{length}(n-1) \) </center>
<center> \( S_{length}(0) = c_1 \) </center>
<p>Note that the span recurrence is exactly the same as the work recurrence. This
should make sense, because there is no opportunity for parallelism in the
<code>length</code> function - we can only pop off elements one by one from the list. In
the recursive case, we must wait for the result of the recursive call on <code>xs</code>,
which means we unavoidably must expend the span of \( S_{length}(n-1) \) -
additionally, we have a data dependency. We cannot execute the addition in <code>1 + length xs</code> until we obtain the result for <code>length xs</code>, which means that we must
sum the time it takes to compute <code>length xs</code> (that being \( S_{length}(n-1) \))
and the time it takes to carry out the addition operation (that being \( c_1 \)).</p>
<p>Now we will begin the task of actually solving the recurrence. They are the same recurrence, so without loss of generality we will solve just the work recurrence.</p>
<p>We know that it has the form of \( W_{length}(n) = c_0 + W_{length}(n-1) \), and
eventually reaches a base case at \( W_{length}(0) = c_1 \). We can &quot;unroll&quot; the
recurrence a few times to see if we can see a pattern, and then arrive at our
answer.</p>
<p>So we start out with \( W_{length}(n) = c_0 + W_{length}(n-1) \), but if we invoke
the definition of \( W_{length}(n-1) \), we can produce \( c_0 + c_0 +
W_{length}(n-2) \), since \( W_{length}(n-1) = c_0 + W_{length}(n-2) \). By doing
the same for \( W_{length}(n-2) \), we get \( c_0 + c_0 + c_0 + W_{length}(n-3) \).
It seems we've hit upon a pattern - each time we &quot;unroll&quot; the definition of
\( W_{length}(n) \), for progressively lower \( n \), we get another \( c_0 \) term
back out. Then, we know that the recurrence should eventually solve to:</p>
<center> \( W_{length}(n) = (\sum_{i=1}^n c_0) + c_1 \) </center>
<p>We will usually omit the \( c_1 \), since it does not matter asymptotically. Then, clearly this is equivalent to \( nc_0 + c_1 \). We see that this closed-form solution is linear in \( n \) - so 
then we have that the work and span of this function is in \( O(n) \), which is consistent with what we would expect if we had &quot;eyeballed&quot; it.</p>
<h2><a class="header" href="#workspan-analysis-trees" id="workspan-analysis-trees">Work/Span Analysis: Trees</a></h2>
<p>First, we will discuss the definition of a binary tree in SML:</p>
<pre><code class="language-sml">datatype tree = Empty 
              | Node of tree * int * tree
</code></pre>
<p>This denotes that a tree is either the constant constructor <code>Empty</code> denoting the empty tree, or a <code>Node</code> that contains an integer value, as well as two <code>tree</code> children, that can themselves be <code>Node</code>s or <code>Empty</code>.</p>
<figure class="aligncenter">
    <img src="concepts/../assets/treeTrans.png" alt="Tree" width="500"/>
    <figcaption><b>Fig 2.</b> Sample binary tree</figcaption>
</figure>
<p>So for instance, we may represent the above tree with <code>Node(Node(Node(Empty, 4, Empty), 3, Empty), 1, Node(Empty, 2, Empty))</code>. Put more fancily:</p>
<pre><code class="language-sml">Node(
    Node(
        Node(
            Empty,
            4,
            Empty
        ),
        3,
        Empty
    ),
    1,
    Node(
        Empty,
        2,
        Empty
    )
)
</code></pre>
<p>Now we will analyze the complexity of finding the size of a tree. Consider the
following implementation for doing so:</p>
<pre><code class="language-sml">fun size (Empty : tree) : int = 0
  | size (Node (L,x,R) : tree) : int = size L + 1 + size R
</code></pre>
<p>First convince yourself that it actually works. It simply recursively finds the
size of the left and right tree, then adds one for the node that it is currently
at. In the empty case, we consider the empty tree to have a size of 0.</p>
<p>The major difference between this function and the previous <code>length</code> function
was that <code>length</code> had one recursive call - <code>size</code> has two. We will need to
reflect this change when we write our recurrences. Additionally, we need a new
variable for our recurrence - we no longer have a list whose length we can
induct on. A similar analogue will be \( n \), the number of nodes in the tree, so
we will take that as our recurrence variable. We will focus first on work.</p>
<p>We will obtain the following work recurrence:</p>
<center> \( W_{size}(n) = c_0 + W_{size}(n_l) + W_{size}(n_r) \) </center>
<center> \( W_{size}(0) = c_1 \) </center>
<p>where we define the number of nodes in the tree \( n = 1 + n_l + n_r \), and
\( n_l \) and \( n_r \) denote the number of nodes in the left and right subtree,
respectively. This follows similarly to our recurrence for <code>length</code> in the
previous part, where <code>c_0</code> is just some constant amount of work that we
necessarily have to do, and the two \( W_{size} \) calls are from the two
recursive calls we make to <code>L</code> and <code>R</code>. </p>
<p>Now, we don't know precisely how big \( n_l \) and \( n_r \) are, with respect to
\( n \). This makes our analysis a little more tricky, but essentially all we need
to do is think of the <em>worst case</em>, as we are interested in the worst-case
asymptotic complexity of this function. For work, however, there is no
worst-case - no matter how the tree is structured, we must visit every node
once, doing a constant amount of work each time. So we should obtain, in the
end, \( W_{size}(n) = nc_0 + c_1 \), which we know is \( O(n) \). So in this case,
we didn't have to think about the structure of the tree. In the next section, it
will matter.</p>
<h2><a class="header" href="#workspan-analysis-balanced-vs-unbalanced-trees" id="workspan-analysis-balanced-vs-unbalanced-trees">Work/Span Analysis: Balanced vs Unbalanced Trees</a></h2>
<p>We will revisit the same example, except from the perspective of span.</p>
<p>The important point to note is that, now, we have two separate recursive calls
that are happening in the recursive call of <code>size</code>. These recursive calls have
no data dependency - neither running depends on the other. This means that they
can be run in <em>parallel</em>, which means that the total span that we compute should
just be the max over both. This is because we can imagine that both of them lead
to different &quot;paths&quot; in our task-dependency graph - we are only interested in
the maximum-length path. So we will run both results, and whichever one takes
longer to return an answer to us is the &quot;limiting reagent&quot; of our computation.</p>
<p>So we will write the span recurrence as follows:</p>
<center> \( S_{size}(n) = c_0 + max(S_{size}(n_l), S_{size}(n_r)) \) </center>
<center> \( S_{size}(0) = c_1 \) </center>
<p>Now note that we are taking the max over the two recursive calls. Now, we cannot
handwave the structure of the tree like we did in the previous part - if one
path is significantly longer than the other, then it will stall the computation
for longer. We still must visit every node, but some of them can occur in
parallel.</p>
<p>We will consider the first case - if we have an unbalanced tree. Suppose that
the tree is heavily unbalanced - akin to a (diagonal) linked list. Without loss
of generality, let it be &quot;pointing&quot; to the left. Then, \( n_l = n - 1 \), and
\( n_r = 0 \). Then, the max over both recursive calls should clearly be that of
\( S_{size}(n-1) \), since it has to compute the size of a larger tree.</p>
<p>So we can update our recurrence and obtain:</p>
<center> \( S_{size}(n) = c_0 + S_{size}(n-1) \) </center>
<center> \( S_{size}(0) = c_1 \) </center>
<p>This recurrence is exactly the same as that of <code>length</code>, so we know that we will
get that \( S(n) \in O(n) \). This should make sense intuitively, since the depth
of the tree is \( n \), and there are dependencies between each level - we cannot
go to the next level until we are done with the current one. So we cannot avoid
having to visit every level sequentially, which results in \( O(n) \) span.</p>
<p>Now, what if we consider a balanced tree? Well, the balanced case would be if
the number of nodes in the left and right subtrees are roughly equal - that is,
\( n_l = n_r = \frac{n}{2} \). We will consider them exactly equal to simplify our
analysis, but we will obtain the same asymptotic answer. Then, we know that the
maximum is just any one of them, since they will have the same span.</p>
<p>So we can update our recurrence and obtain:</p>
<center> \( S_{size}(n) = c_0 + S_{size}(\frac{n}{2}) \) </center>
<center> \( S_{size}(0) = c_1 \) </center>
<p>This is slightly different than our <code>length</code> recurrence. We will try unrolling
to make sense of this recurrence.</p>
<p>We have that \( S_{size}(n) = c_0 + S_{size}(\frac{n}{2}) \). Plugging in the
recursive definition of \( S_{size}(\frac{n}{2}) \), we get that this expands to
\( c_0 + c_0 + S_{size}(\frac{n}{4}) \), which by the same trick expands to \( c_0+ c_0 + c_0 + S_{size}(\frac{n}{8}) \), 
and so on and so forth. We note that we
are dividing the number of nodes by 2 each time - and we know that we can divide
\( n \) by two roughly \( \log_2(n) \) times. So in total, we can solve the
summation of \( S_{size}(n) \) as \( S_{size} = (\sum_{i=1}^{\log_2(n)} c_0) +
c_1 \).</p>
<p>So then this simplifies to \( S_{size}(n) = \log_2(n)c_0 + c_1 \). This is a
logarithmic function of \( n \), so we get that the span of <code>size</code> is in \( O(\log
n) \). Thus, we obtain a different span for balanced trees versus unbalanced
trees - balanced trees are more efficient and parallelism-friendly.</p>
<h2><a class="header" href="#workspan-analysis-size-dependent-operations" id="workspan-analysis-size-dependent-operations">Work/Span Analysis: Size-dependent Operations</a></h2>
<p>In these past two examples, we have only seen examples that did a constant
amount of non-recursive work. We will now analyze a function that does
non-recursive work that is a function of the input size \( n \). This will result
in different kinds of recurrences. First, however, we will digress briefly to motivate the example that we will analyze.</p>
<blockquote>
<p><strong>[Case Study: Tree Traversal]</strong></p>
<p>When analyzing trees, it is often prudent to utilize <em>tree traversal</em>, or a
systematic way of enumerating the elements in a tree. There are multiple
different ways to do this, depending on what your intentions are - a few namely
being preorder, inorder, and postorder traversal.</p>
<p>With these different methods of traversal, we can turn a tree into a different
kind of ordered data structure, such as a list or sequence. This can come in
handy when we desire future fast access to any arbitrarily ranked node in the
tree, or if we want to convert it for purposes of printing, for instance.</p>
<p>Each traversal is characterized by a certain &quot;strategy&quot; of traversal, depending
on how it ranks the three possible directions that it can go - root, left, and
right. Inorder traversal, for instance, is characterized by left-root-right
prioritization - this means that it goes left first, and if it can't go left,
then it visits the root node, and otherwise it goes right. Note that this does
not mean that it visits the root of the left subtree first - it simply reruns
the same process on the entire left subtree. No matter what the traversal
strategy is, a node is never actually visited until the &quot;root&quot; action is taken.
Preorder traversal is root-left-right, and postorder is left-right-root.
Examples of preorder and inorder traversals (the most common you will see in
this book) are below.</p>
</blockquote>
<figure class="aligncenter">
    <img src="concepts/../assets/traversals.png" alt="traversal" width="650"/>
    <figcaption><b>Fig 3.</b> An example of a preorder traversal (left) and inorder traversal (right) of a binary tree, with visited nodes labeled in ascending order </figcaption>
</figure>
<blockquote>
<p>Tree traversals can also come in handy when generating different notations for
mathematical expressions when represented in the form of an <em>binary expression
tree</em>, which has nodes that consist of either a <em>numeric constant</em>, which has
no children, a <em>unary operation</em> with a single child, or a <em>binary operation</em>
with two children. For instance, a binary expression tree for the mathematical
expression \( (4-1) * 2 \) is shown below.</p>
</blockquote>
<figure class="aligncenter">
    <img src="concepts/../assets/optree.png" alt="optree" width="500"/>
    <figcaption><b>Fig 4.</b> A binary expression tree for the expression \( (4-1) * 2 \)</figcaption>
</figure>
<blockquote>
<p>With inorder traversal of this expression tree, we can generate the constants
and symbols in exactly the same order as \( (4-1) * 2 \), which is how we would
normally interpret it. Preorder and postorder traversal, however, result in an
interesting interpretation - what is known as <em>prefix</em> (or <em>Polish</em>) and <em>postfix</em> (or <em>Reverse Polish</em>) notation.</p>
<p>In prefix notation, by using preorder traversal, we obtain the expression \( * - 4 1 2 \), which is how we would interpret the same expression if all of our operators appeared before their operands. Similarly, with postorder traversal, we obtain the expression \( 4 1 - 2 * \) in postfix notation. Prefix and postfix notation have significance in their lack of ambiguity - while infix notation is easy for humans to read, it requires parentheses sometimes to denote how operator precedence takes place. Prefix and postfix notation have no such flaw - they are unambiguous in how operations take place. In programming language interpreters, such notations are sometimes used to represent mathematical expressions.</p>
</blockquote>
<p>Such a digression serves as motivation for the next function that we will analyze - which is writing the preorder traversal of a tree in SML. The code looks like this:</p>
<pre><code class="language-sml">fun preord (Empty : tree) : int list = []
  | preord (Node(L, x, R) : tree) : int list = x :: (preord L @ preord R)
</code></pre>
<p>We can readily see that this follows the root-left-right order that we specified
earlier for preorder traversal. Recall that <code>@</code> is the function for list
concatenation, and has a complexity of \( O(n_l) \) in \( n_l \), the size of the
left input list. Thus, as stated before, this function has a non-constant amount
of work at each recursive call - we must evaluate <code>@</code> of the result of <code>preord L</code> and <code>preord R</code>, which is a function of \( n \), the number of nodes in the
tree.</p>
<p>We will analyze only the balanced case for this function. We invite the reader
to think about the unbalanced case on their own.</p>
<p>For the recursive case, we know that \( W_{preord}(n) \) will take the form of 
\( c_0 + W_@(n_l) + W_{preord}(n_l) + W_{preord}(n_r) \). By our balanced assumption, 
we know \( n_l = n_r = \frac{n}{2} \), so we can write our work recurrence as:</p>
<center> \( W_{preord}(n) = c_0 + \frac{n}{2}c_1 + 2W_{preord}(\frac{n}{2}) \) </center>
<center> \( W_{preord}(0) = c_2 \) </center>
<p>Note that the term \( W_@(n_l) \) is a recurrence in terms of \( n \), the size of the left list given as input to <code>@</code>. 
Since we know that the work complexity of <code>@</code> is \( O(n) \), we can replace \( W_@(\frac{n}{2}) \) with \( \frac{n}{2}c_1 \), 
which is simply some constant \( c_1 \), scaled by a linear factor of the input \( \frac{n}{2} \). This is how we will generally 
deal with analyzing the complexity of functions that make use of helper functions.</p>
<p>We will make use of a new method to solve this recurrence - the Tree Method.</p>
<blockquote>
<p><strong>[Tree Method]</strong> The <em>tree method</em> is a method for solving recurrences of certain recurrences that sum to the same quantity across levels, and usually have multiple recursive calls. In essence, if each level has the same amount of computation, then the recurrence solves to the (number of levels) * (amount at each level).</p>
</blockquote>
<p>The below diagram illustrates the Tree Method.</p>
<figure class="aligncenter">
    <img src="concepts/../assets/treemethodTrans.png" alt="Tree method" width="1200"/>
    <figcaption><b>Fig 5.</b> An illustration of the Tree Method for the recurrence of preord.</figcaption>
</figure>
<p>We will now explore exactly how we arrived at this conclusion.</p>
<p>First, note that this tree exists as a result of the recurrence. We used the
code to specify the recurrence, and then the recurrence itself described this
tree. It has a branching factor of 2 (that is, two children of each node that
are non-leaves) since the recursive case of the recurrence has two recursive
calls, and at each level the size of the input changes. Since the recursive
calls are called on inputs of size \( \frac{n}{2} \), each level results in a
division by two of the input size.</p>
<p>Additionally, we know that the amount of work at each node (of input size \( n \))
is necessarily \( c_1 \frac{n}{2} \). There is technically also a \( c_0 \) term,
but we will omit it since it is asymptotically dominated by \( c_1 \frac{n}{2} \).
The precise non-recursive work done by each &quot;node&quot; is specified slightly down
and to the left of each node. Individually, they don't look very nice to sum
over - at level \( i \), it appears the work at each node is \( c_1
\frac{n}{2^{i+1}} \). However, level \( i \) also has \( 2^i \) nodes, by the
branching nature of the recurrence tree. As such, the total amount of work done
at level \( i \) is just \( c_1 \frac{n}{2^{i+1}} * 2^i = c_1 \frac{n}{2} \), which
is not a function of the level \( i \).</p>
<p>As such, each level has the same amount of work - which is very convenient, as
we can now just take that quantity and multiply it by the number of levels. So
in total, when we solve out the recurrence, we should obtain that \( W(n) =
(\sum_{i=1}^{\log_2(n)} c_1\frac{n}{2}) + c_2n \), since the \( c_2n \) term is
separately obtained from the base level, due to the \( n \) leaves that each have
\( c_2 \) work. </p>
<p>The term \( \sum_{i=1}^{\log_2(n)} c_1\frac{n}{2} \) thus goes to \( \frac{c_1}{2}
n\log_2(n) \), so in total we obtain that \( W(n) = \frac{c_1}{2} n\log_2(n) +
c_2n \), which is in \( O(n \log n) \). So we're done.</p>
<p>The tree method is really nothing more than just a visual way to view the
recurrence - it is possible to achieve the same effect by just writing a
summation. It is sometimes more intuitive to try and visualize, however, and for
recurrences where the levels sum to the same amount, the tree method is very
effective. However, not all recurrences exhibit such behavior, and it's hard to
know <em>a priori</em> whether a given recurrence is such a one. Nevertheless, it is a
powerful method and sufficient for many purposes.</p>
<p>We omit the span analysis of this function for the reader.</p>
<h2><a class="header" href="#conclusions" id="conclusions">Conclusions</a></h2>
<p>Asymptotic analysis is a very important technique for attempting to categorize the efficiency of programs. Moreover, it is not enough to simply find the asymptotic <em>sequential</em> complexity of a function - parallel computation is becoming increasingly more important, and purely sequential analyses are not representative of real-world algorithms. Work and span analyzed through recurrence relations form a powerful framework for examining the complexity of recursive functions, which is robust enough to classify many kinds of algorithms.</p>
<h1><a class="header" href="#datatypes" id="datatypes">Datatypes</a></h1>
<h1><a class="header" href="#parametric-polymorphism" id="parametric-polymorphism">Parametric Polymorphism</a></h1>
<p>Type safety is a very powerful concept, one that lets us pin down the space of
allowable inputs to only a narrow space of values. In this way, we can ensure
that the function is only allowed to be applied to those arguments that we are
interested in, making any other computations illegal. Sometimes, however, we are
interested in making a function more <em>general</em>, with arguments that can somehow
<em>range over types</em>. We will see how SML achieves this with <em>parametric
polymorphism</em>, which is a separate concept than other forms of polymorphism that
you may have seen before.</p>
<h2><a class="header" href="#motivation-2" id="motivation-2">Motivation</a></h2>
<p>Suppose that we wanted to write a length function for lists.</p>
<p>Well first, we might want to specify. What <em>type</em> of list? Let's say that we
first have int lists.</p>
<p>Well, the implementation is easy:</p>
<pre><code class="language-sml">fun lengthInt ([] : int list) : int = 0
  | lengthInt (x::xs : int list) : int = 1 + lengthInt xs
</code></pre>
<p>But suppose that we don't only want the length of int lists, but also the length
of string and char lists. Well then, we'll need to define a few more functions:</p>
<pre><code class="language-sml">fun lengthString ([] : string list) : int = 0
  | lengthString (x::xs : string list) : int = 1 + lengthString xs

fun lengthChar ([] : char list) : int = 0
  | lengthChar (x::xs : char list) : int = 1 + lengthChar xs
</code></pre>
<p>This becomes unnecessarily tedious. As we can see, other than the name of the
function and the type annotations, these functions have exactly the same code.
Nothing about the functions themselves make use of the fact that the lists in
question contain ints, strings, or chars - they are merely manipulated as
arbitrary elements. We would like to be able to write a <code>length</code> function that
works on a list of any type.</p>
<h2><a class="header" href="#the-idea" id="the-idea">The Idea</a></h2>
<p>We've seen something similar to this - we know that lists of all kinds exist. No
matter whether it is an <code>int list</code>, a <code>string list</code>, or a <code>char list</code>, we know
that <code>::</code> is always valid to use when consing an element onto a list of the
appropriate type. Indeed, we say that <code>::</code> has type <code>t * t list -&gt; t list</code> for
all types <code>t</code>. Cons is thus <em>polymorphic</em>, it can be used on many different
types (though never two at the same time, for instance <code>1::[&quot;hello&quot;]</code> is still
ill-typed). </p>
<p>This has been something of an alternative definition for what we will be
discussing in this chapter - parametric polymorphism. Seen in this way, all
polymorphic functions are <em>parameterized</em> by a <em>type variable</em> that ranges over
types. We will go more in depth into this idea.</p>
<blockquote>
<p><strong>[Type variable]</strong> A type variable is a type that is quantified over types -
that is, it can specifically take on the form of many types. They are
enumerated as <code>'a</code>, <code>'b</code>, <code>'c</code>, and so on, and they are referred to by Greek
letters. For instance, <code>'a</code> is &quot;alpha&quot;, <code>'b</code> is &quot;beta&quot;, <code>'c</code> is &quot;gamma&quot;, and
so on.</p>
</blockquote>
<p>Type variables are themselves valid types. As such, we can rewrite <code>length</code> as:</p>
<pre><code class="language-sml">fun length ([] : 'a list) : int = 0
  | length (x::xs : 'a list) : int = 1 + length xs
</code></pre>
<p><code>'a</code> is quantified over all types, so <em>no matter</em> what type the input list to
<code>length</code> is, it will work correctly, as SML will use <em>type inference</em> to
determine what the proper type of the <code>length</code> function should be, in any given
context. Note that <code>'a</code> is a <em>variable</em>, and as always, in proofs, we must
quantify our variables. <code>'a</code> and other type variables thus implicitly correspond
to having a &quot;for-all&quot; quantifier in front of it - so we say that an expression of type <code>'a</code> has type <code>t</code>, for all types <code>t</code>. We further note that this is really syntactic sugar for the notation:</p>
<pre><code class="language-sml">fun 'a length ([] : 'a list) : int = 0
  | length (x::xs : 'a list) : int = 1 + length xs
</code></pre>
<p>This specifies that the length function itself is parameterized over <code>'a</code>.
Although <code>'a</code> is a &quot;parameter&quot; of <code>length</code>, it is not truly an argument - we do
not explicitly pass in the type to <code>length</code>. In an abstract sense, however, we
do, as each &quot;instantiation&quot; of <code>length</code> has been &quot;supplied&quot; an argument to <code>'a</code>
to produce a &quot;copy&quot; of the function. You can think of it as if <code>length</code> has
infinitely many different variations that can be selected, depending on what the
given type is inferred to be. Note that the &quot;type&quot; that is chosen does not
necessarily need to be a concrete type - it may itself compose of type
variables. For instance, consider the following code:</p>
<pre><code class="language-sml">fun tupleLength [] = 0
  | tupleLength ((x, y)::xys) = 1 + length xys
</code></pre>
<p>Disregard the rather strange implementation, which is a rather arcane way of
rewriting <code>length</code> with unnecessary overhead. In this example, we can see that
the list <code>xys</code> contains tuples of two elements, the types of which are unknown
to us. Without knowing a concrete type, we can only conclude that the type of
<code>length</code> is <code>('a * 'b) list -&gt; int</code>. This is because the elements of the tuple
do not necessarily have to be correlated with each other - <code>'a</code> and <code>'b</code> are
thus independent, though they <em>could</em> be instantiated to the same type. As such,
we have taken a type variable and replaced it with two more type variables,
which gives us a little more information but still quite a bit of leeway.
<code>tupleLength</code> is thus itself still polymorphic, with the same type of <code>('a * 'b) list -&gt; int</code>.</p>
<p><strong>NOTE:</strong> We have now reached a point where we will begin to omit explicit type
annotations, as they tend to unnecessarily constrain the types of functions. It
is also a good exercise to be able to understand conceptually how type inference
is carried out, which is covered more in the next section.</p>
<p>An important principle to note, however, is that an <code>'a</code> type does not magically
&quot;just work&quot; with regards to type safety. For instance, let us consider the
following code fragment, which is ill-typed:</p>
<pre><code class="language-sml">fun inc (x : 'a) : int = 1 + x
</code></pre>
<p>Note that, in this case, type annotations have actually worked against us! Had
we removed the type annotations, this code would compile. The reason why this
code is ill-typed is because, while we are allowed to use a type <em>more
generally</em> than it actually is, we cannot use a polymorphic type <em>more
specifically</em>. The reason for this is because if we think about it as if we
explicitly passed in some type variable, in the <em>scope of the function</em> <code>inc</code>,
<code>inc</code> has fixed <code>'a</code> to be some type. It then attempts to add 1 to <code>x</code>, which is
a value of that fixed, arbitrary type. However, we cannot add 1 to a value of
any type - we can only safely add 1 to <code>x</code> if we know that <code>x</code> has type <code>int</code>.
If <code>'a</code> were instantiated to be a <code>string</code>, it would violate type safety to
allow this code to compile. As such, we <em>cannot</em> explicitly type annotate <code>x</code> to
be of type <code>'a</code>, as it is used <em>more specifically</em> than that in the body of the
function.</p>
<h2><a class="header" href="#other-forms-of-polymorphism" id="other-forms-of-polymorphism">Other Forms of Polymorphism</a></h2>
<p>A similar idea of extending functions to working on many types is exhibited by
<em>equality types</em>, which are a behind-the-scenes process that you have already
been exposed to. Consider the type of the function <code>=</code> - the equality operator.
Clearly, it cannot have type <code>'a * 'a -&gt; bool</code>, since some types don't make
sense to compare for equality. For instance, how would you compare whether or
not a real is equal to another? Machine representations are finite, so asking
the question is bound to introduce problems. Another difficulty is in <em>function
types</em> - determining if two arbitrary functions are extensionally equivalent is
an uncomputable problem (closely related to the Halting Problem). As such, we
would like <code>=</code> to work on a wide spectrum of types, but also not work on
another, also very wide spectrum of types.</p>
<p>To do this, SML has a concept of <em>equality types</em>. The type variable <code>''a</code> (and
<code>''b</code> and <code>''c</code>, as normal) are not quantified over all types, but merely all
equality types. This includes <code>int</code>, <code>bool</code>, <code>string</code>, and any datatype built up
from non-equality types, among others. Thus, the <code>=</code> operator actually has type
<code>''a * ''a -&gt; bool</code>, so as to only work on compatible types. </p>
<p><strong>NOTE:</strong> Note that the polymorphism demonstrated by <code>length</code> is of a different
flavor than that of <code>+</code>, <code>*</code>, or other overloaded functions. The overloading of
basic arithmetic functions to work on ints and reals is more in line with what
might be referred to as &quot;ad hoc&quot; polymorphism, which is merely the compatibility
of a single operator with several possibly heterogeneous implementations, with
the precise implementation being chosen by context (such as type, in this case).
It is thus important to note that while parametric polymorphism identifies a
single, <em>general</em> implementation with many types, ad hoc polymorphism identifies
several different implementations with different use cases. Ad hoc polymorphism
is noticeably more inelegant than parametric polymorphism, but it is useful in
the cases that you only have a small subset of types to extend an operator to.</p>
<h2><a class="header" href="#type-inference" id="type-inference">Type Inference</a></h2>
<p>Duiring compilation, SML will often need to determine exactly what the type of
the expression that we are looking at. This is not so different of a problem
than type-checking, however. On a high level, SML simply assigns everything a
very general type, and then begins looking at clues from the context so as to
narrow down what the &quot;most general type&quot; is. By &quot;most general type&quot;, we usually
mean the most general type an expression can have, meaning that we do not use
specific instances of polymorphic expressions, but just the polymorphic type
itself. It is valid to say that the <code>length</code> function has type <code>int list -&gt; int</code>, but its most general type is <code>'a list -&gt; int</code>.</p>
<blockquote>
<p><strong>[Type Inference]</strong> A procedure employed by type systems to <em>infer</em> the type
of expressions and functions, even when not explicitly given those types.</p>
</blockquote>
<p>This is how we can, for instance, determine that the function <code>fn x =&gt; x + 1</code>
must have type <code>int -&gt; int</code>. <code>x</code> is not deliberately stated to have any type,
but we know that it wouldn't make sense for <code>x</code> to be any other type than <code>int</code></p>
<ul>
<li>it would otherwise not type-check. Note that <code>x</code> cannot be <code>real</code>, since <code>+</code>
cannot have an input type of <code>real * int</code>.</li>
</ul>
<p>We might also think of it like this - consider the expression <code>fn x =&gt; x + 1</code>.
Most generally, we know that its type should an instance of type <code>'a</code>. Moreover, we see that it is a lambda expression, so it must now be an instance of <code>'a -&gt; 'b</code>. The input is <code>x</code>, so we assign <code>x</code> to be an instance of type <code>'a</code>. We then attempt to apply the <code>+</code> operator to <code>x</code>, so for this to typecheck, <code>x</code> must have type <code>int</code>. The outcome of an <code>int</code> and an <code>int</code> with <code>+</code> should be an <code>int</code>, and that's the entire function body, so the whole expression has type <code>int -&gt; int</code>.</p>
<h2><a class="header" href="#conclusions-1" id="conclusions-1">Conclusions</a></h2>
<p>Parametric polymorphism offers us a clean and elegant way to extend <em>general
implementations</em> to work across a spectrum of types. In this way, we can still
preserve type safety while allowing us to avoid writing out the same
implementations for many different types. Type inference also conveniently lets
us omit manually determining the type of our code, instead being able to
determine it from context. Ultimately, parametric polymorphism is a simple idea
that offers us a great deal of versatility.</p>
<h1><a class="header" href="#higher-order-functions" id="higher-order-functions">Higher Order Functions</a></h1>
<p>At this point, we've explored the concept of
computation as <em>evaluation</em>, passing around values and reducing expressions to
values as well. We have seen how we are allowed a great deal of versatility
while maintaining type safety in SML's type system, and how we can construct
arbitrary datatypes to be passed around as <em>first class citizens</em>, that is being
able to be manipulated the same as any other value. We will now discuss what is
considered one of the most powerful tools available in functional programming
languages - that is, the exploitation of <em>functions themselves</em> as values, with
which we can further parameterize our functions and results.</p>
<h1><a class="header" href="#currying-and-staging" id="currying-and-staging">Currying and Staging</a></h1>
<p>Suppose that we are interested in writing a function
that adds two numbers. This is fairly simple - this is not a new concept to us.</p>
<pre><code class="language-sml">fun add (x, y) = x + y 
</code></pre>
<p>Then this function should clearly have type <code>int * int -&gt; int</code>. We also know
that this notation is really just syntactic sugar for the following: </p>
<pre><code class="language-sml">val add = fn (x, y) =&gt; x + y 
</code></pre>
<p>It binds the lambda expression that takes in a tuple of two integers and adds
them together to the identifier of <code>add</code>. Yet with our knowledge of expressions
and values, it is not too outlandish to write the following instead: </p>
<pre><code class="language-sml">fun addCurry x = fn y =&gt; x + y 
</code></pre>
<p>What might be the type of this function? Well, we know that <code>addCurry</code> takes in
a value <code>x</code>, which should be an <code>int</code>, since it is summed with <code>y</code>. It then
returns a lambda expression that takes in that same <code>y</code>, and returns the sum,
which is an <code>int</code>. It seems to us that the type should be <code>int -&gt; (int -&gt; int)</code>.
This is an example of a <em>curried</em> function, and one of the first examples we
will see of a <em>higher-order function</em>.</p>
<blockquote>
<p><strong>[Higher-Order Functions]</strong> A <em>higher-order function</em> is a function that
takes in other functions as input, or returns a function as output.</p>
</blockquote>
<blockquote>
<p><strong>[Currying]</strong> Named after mathematician/logician Haskell Brooks Curry,
<em>currying</em> is the act of transforming a function that takes multiple arguments into a
function that returns a function that takes the remaining arguments.
Intuitively, it separates the arguments into a series of function
applications, instead of all at once. We may refer to a general higher-order
function that returns a function as a curried function.</p>
</blockquote>
<p>An important note is that in the type <code>int -&gt; (int -&gt; int)</code>, the parentheses are
unnecessary. This is because type arrows are <em>right-associative</em>, in the same
way that <code>::</code> is. This means that there is already an implicit parentheses in
the type <code>int -&gt; int -&gt; int</code> - the function simply takes in an integer and
returns a function from <code>int -&gt; int</code>. This is thus a separate type than <code>(int -&gt; int) -&gt; int</code>, which is a function that takes in a function from <code>int -&gt; int</code> and
returns an integer.</p>
<p>Note that in the curried example of <code>addCurry</code> we wrote above, this is really
syntactic sugar for the following: </p>
<pre><code class="language-sml">val addCurry = fn x =&gt; fn y =&gt; x + y
</code></pre>
<p>Not being ones to skimp on the syntactic sugar (which perhaps spells danger for
our syntactic blood sugar levels), we can take this one step further. We can
write the exact same declaration in a more concise way, using the form: </p>
<pre><code class="language-sml">fun addCurry x y = x + y 
</code></pre>
<p>This thus will curry our arguments for us, when we separate them by a space. </p>
<p>Note that our implementations of <code>addCurry</code> and <code>add</code> are <em>not</em> extensionally
equivalent - for the simple reason that they do not even have the same type!
They do, however, in a sense <em>correspond</em>, in that they seem to do the <em>same
thing</em> - that is, add numbers together. The manner in which they do so is
entirely disparate, however. </p>
<p>It is important to note that currying our functions gives us a notion of
<em>partial application</em>, where we can give a curried function only <em>some</em> of its
&quot;arguments&quot;. This lends us to further specialization and modularity based on the
use case and amount of information available. This is discussed more in the
coming section. </p>
<h2><a class="header" href="#revisiting-extensional-equivalence" id="revisiting-extensional-equivalence">Revisiting Extensional Equivalence</a></h2>
<p>In previous chapters, we have explored the idea of extensional equivalence, and 
constructed a definition for extensional equivalence that covered two cases - 
the function case and the non-function case.</p>
<p>We seemed to agree on a meaning that said that, for non-function values, two
values are extensionally equivalent if they are the <em>same value</em>, which is an
perhaps an ill-justified definition that may leave a bad taste in one's mouth, 
but ultimately boils down to our intuitive notion that, yes, some values are 
just the <em>same</em> and we can't really do much more than question that. For 
instance, we can see that <code>(1, 2, &quot;hi&quot;)</code> and <code>(1, 2, &quot;hi&quot;)</code> are the &quot;same&quot;, 
and neither are the same as <code>(2, 1, &quot;hello&quot;)</code>. For functions, however, we 
decided on a slightly more appeasing definition that defined a function by 
its <em>input-output</em> behavior. We restate the definition below:</p>
<blockquote>
<p><strong>[Extensional Equivalence (Functions)]</strong> We say two expressions <code>e : t1 -&gt; t2</code> and <code>e' : t1 -&gt; t2</code> for some types <code>t1</code> and <code>t2</code> are extensionally
equivalent if for all values <code>x : t1</code>, <code>e x</code> \( \cong \)<code>e' x</code>.</p>
</blockquote>
<p>It is our hope that we are now in a place to properly appreciate this
definition. For functions that have type <code>int -&gt; int</code>, this is a fairly
straightforward definition - these functions are extensionally equivalent if,
for every integer that we give them, they return the same int. However, what
about curried functions? Our definition, in light of this new concept, is that
curried functions are extensionally equivalent if <em>the functions that they
return are extensionally equivalent</em>.</p>
<p>No matter how deeply nested this currying takes place, this definition will
suffice. Types must be finite, so we must eventually reach a point where we can
say that values are &quot;the same&quot; (excluding the existence of non-equality types, perhaps). 
We can see now that this idea of extensional equivalence is elegantly
compatible with the existence of curried functions, being a recursive definition
much in the same way that the <code>datatype</code>s that we declare or the <code>fun</code>ctions
that we write are. </p>
<h2><a class="header" href="#staging" id="staging">Staging</a></h2>
<p>With curried functions, we can have much more deliberate control over <em>when</em> a
function does evaluation, particularly with respect to the inputs that it
receives.</p>
<p>Consider an analogy. Suppose you have math homework to do, but you left your
calculator at home. A more lazy-minded student might procrastinate, thinking
that they would only start once they got home, but a more pragmatically-minded
individual might simply start on the problems that don't require a calculator.
The idea of staging is that we can reap efficiency benefits for certain
problems when facing a scarcity of information, by simply doing computations
that require the arguments that are at hand first. We thus make a distinction
between functions that must have all of their arguments to do useful work, and
those who do not.</p>
<p>For instance, take the addition function.</p>
<pre><code class="language-sml">fun add (x : int, y : int) : int = x + y
</code></pre>
<p>This is not a function that we would categorize as being able to do &quot;useful
work&quot; with a single one of its arguments. Even if we were to curry <code>add</code>, with
only one <code>int</code> it can't really do anything but simply wait for the second
argument. In this case, the efficiency benefits are marginal at best. The
computations are somewhat &quot;dependent&quot; - we need access to both arguments in
order to do anything meaningful. </p>
<p>Consider a more contrived example:</p>
<pre><code class="language-sml">(* contrived : int -&gt; int -&gt; int *)
fun contrived x y =
    let
        val z = horrible_computation x (* this takes 3 years *)
    in
        y + z
    end
</code></pre>
<p>The function <code>contrived</code> takes in two arguments <code>x</code> and <code>y</code>. It then performs
some transformation on <code>x</code> using the function <code>horrible_computation</code> (which
takes 3 years to run, unfortunately), and then adds <code>y</code> to the result of that
transformation <code>z</code>. </p>
<p>Suppose that we are interested in computing the results of <code>contrived 4 2</code> and
<code>contrived 4 5</code>, for no reason other than because we can. Then, clearly
evaluation of those two expressions will take 3 years each (per
<code>horrible_computation</code>'s horrible computational nature) - totalling up to six
years! This is far too long, and we want to do better.</p>
<p>One thing that we note is that almost all of the work that we expended in
computing <code>contrived 4 2</code> and <code>contrived 4 5</code> was in evaluating
<code>horrible_computation 4</code>. This computation took us 3 years, but we repeated it
twice! In both of queries we made, we had to compute the exact same thing, which
led to major inefficiencies. The rest of the work of <code>contrived</code> was negligible
compared to the overhead of <code>horrible_computation</code>. It seems that we should be
able to achieve better results.</p>
<p>Consider the following definition instead:</p>
<pre><code class="language-sml">(* contrivedStaged : int -&gt; int -&gt; int *)
fun contrivedStaged x =
    let
        val z = horrible_computation x (* this still takes 3 years *)
    in
        fn y =&gt; y + z
    end
</code></pre>
<p>Now, we have <em>staged</em> <code>contrived</code>. <code>contrivedStaged</code> still has the same type as
<code>contrived</code>, but it behaves slightly differently. It is not too difficult to see
that <code>contrived</code> is extensionally equivalent to <code>contrivedStaged</code>, but we have
made a slightly more optimal change with regards to SML's semantics.</p>
<p>Now, instead of waiting for the second argument <code>y</code> to begin executing
<code>horrible_computation x</code>, <code>contrivedStaged</code> does so immediately after receiving
<code>x</code>. This is clearly better - there was no point to wait for <code>y</code> in the first
place, since <code>horrible_computation</code> does not depend on it. So now we can execute
the following code fragment:</p>
<pre><code class="language-sml">val intermediate = contrivedStaged 4
val ans1 = intermediate 2
val ans2 = intermediate 5
(* takes 3 years in total *)
</code></pre>
<p>We can do this because <code>contrivedStaged 4</code> computes the result of
<code>horrible_computation 4</code>, and then <em>stores the result</em> in the closure of the
function that it returns. This means that, in the scope of <code>intermediate</code>, it
contains the answer that was common to both of the expressions we wrote earlier.
Now, we can execute the step of <code>y + z</code> (which is nearly instantaneous), cutting
our runtime in half. Now, we can obtain the result of <code>contrived 4 2</code> and 
<code>contrived 4 5</code> in only 3 years (though to evaluate both of those expressions 
themselves would still take 6 years!).</p>
<p>It is important to note that currying is <em>not</em> the same thing as staging.
<code>contrived</code> was curried, but not staged optimally - we made a change that, even
though it had the same type, let us structure our queries in a more optimal
manner. This is an important idea with many applications, such as when building
up a data structure to make queries to, or in graphics when a lot of work must
first be done to preprocess the given data. </p>
<h1><a class="header" href="#control-flow" id="control-flow">Control Flow</a></h1>
<p>Programs inherently are composed of a series of <em>steps</em>. Depending on the
context, syntax, and semantics of the programming language in general, we arrive
at a certain <em>prescribed order</em> in which instructions are executed (at least for
sequential programs). It is often the case that, according to small differences
in state or environment, <em>control</em> may be affected, causing different
instructions to be executed. In this chapter, we will discuss two control flow
constructs, namely continuations and exceptions, that can allow us to more
easily and cleanly write functions that need to have complex control flow
behavior, or in other words, complicated decision-making.</p>
<style>
.center{
    display: block;
    margin-left: auto;
    margin-right: auto;
}
figure figcaption {
    text-align: center;
}
</style>
<h1><a class="header" href="#continuation-passing-style" id="continuation-passing-style">Continuation Passing Style</a></h1>
<p>We have seen how we can write functions that are <em>tail recursive</em>, in that they
only make recursive calls as <em>tail calls</em>, where the recursive calls is the last
thing that the function does (i.e. there is no deferred work). This commonly was
realized by implementing the tail-recursive function with an <em>accumulator</em>,
which simply stored the intermediate values that were computed. In this section,
we will explore an concept known as <em>continuation-passing style</em>, which sees the
use of <em>functions as accumulators</em>, which lets us use more explicit logic when
encoding the control flow of our programs, as well as the intermediate results
of our computations.</p>
<h2><a class="header" href="#continuation-passing-style-the-idea" id="continuation-passing-style-the-idea">Continuation Passing Style: The Idea</a></h2>
<p>Consider the computation of <code>(2 + 3) * 4</code>.</p>
<p>Clearly, there is an ordering to how we should evaluate this. We should sum <code>2</code>
and <code>3</code> first, then take the <em>result of that</em> and multiply it by <code>4</code>. There is
kind of a catch here, that is quickly glossed over by our human brains - we
refer to &quot;the result of that&quot; rather casually. We haven't explicitly named it,
but we nonetheless make an appeal to intuition to get our point across.</p>
<p>How else might we represent this computation? Well, we could use lambda
expressions, and then use the power of function application to compute the
result. Then, we might obtain that this is akin to evaluating <code>(fn res =&gt; res * 4) (2 + 3)</code>. This would be a more direct translation of the idea of &quot;add 2 and 3,
then pass the result of that to 4&quot;. We note that, in the process, we have
explicitly made clear what we mean by &quot;the result of that&quot; - it is now bound to
a name, that being <code>res</code>.</p>
<p>We can take this one step further. If we think about it a bit more, we might
want to consider starting at a &quot;single&quot; value, so that we don't have to consider
the operation of <code>2 + 3</code> as one step. Then, we might instead write &quot;take 2, add
the previous result to 3, and then multiply the previous result by 4&quot;. Clearly,
we have now made it deliberate that we are passing around a <em>single value</em> that
we are performing operations on at each step. How would we write this as a
lambda expression, however?</p>
<p>We might write <code>(fn res =&gt; (fn res2 =&gt; res2 * 4) (res + 3)) 2</code> to encode the
previous instructions. This essentially makes <code>res</code> the <em>first</em> &quot;previous
result&quot;, and then the result of <code>2 + 3</code> is <code>res2</code>, the <em>second</em> &quot;previous
result&quot;. Make sure you understand what is happening here - we are binding <code>2</code> to
the identifier <code>res</code>, then binding the result of <code>res + 3</code> to the identifier
<code>res2</code>.</p>
<p>However, it is still on us to provide the value of <code>2</code>. We to somehow encode the
notion of the <em>computation</em> of <code>(2 + 3) * 4</code>, not necessarily evaluating the
expression ourselves. We know that placing an expression within the confines of
a lambda expression will &quot;freeze&quot; the computation, causing it to only resume
once the lambda expression is given an input, so what we can do is simply do the
same with a trivial input. Our trivial input here will be <code>()</code>, or unit, since
we always have access to it, and there is only one value of type <code>unit</code>.</p>
<p>So somehow, we can encode the idea of this expression with <code>(fn () =&gt; (fn res =&gt; (fn res2 =&gt; res2 * 4) (res + 3)) 2)</code>. Seen in this way, we have somehow encoded
the desired expression not by actually executing it, but forming some large
function <em>a priori</em> that essentially does the same thing. We thus form a correspondence between evaluating an expression by <em>carrying out each step in real time</em> and by <em>writing out the steps to be done at a later time</em>. We hope to show that two are really equivalent - this will be important to understand for later.</p>
<h2><a class="header" href="#continuation-passing-style-a-case-study" id="continuation-passing-style-a-case-study">Continuation Passing Style: A Case Study</a></h2>
<p>We will now discuss continuation passing style more explicitly.</p>
<p>It is hopefully clear that the previous example of <code>(fn () =&gt; (fn res =&gt; (fn res2 =&gt; res2 * 4) (res + 3)) 2)</code> encodes, in some form, the <em>idea</em>
of the computation of the expression <code>(2 + 3) * 4</code>. Somewhat key, however, is
that computation <em>does not execute</em> until we actually feed a unit to it. It is
important to note the distinction between <em>doing something</em> and <em>writing the
instructions to do something</em>. A continuation can be thought of as a
<em>blueprint</em>, or a <em>contingency plan</em>. We will expand more on what we mean by
this shortly, but a continuation essentially represents <em>what instructions need
to be executed</em>. This is a very powerful idea, because programs can continuously
alter continuations by adding more instructions or even executing different
continuations in order to determine what computations ultimately need to be
executed.</p>
<p>We will first consider a simple example before going into the definition.</p>
<pre><code class="language-sml">(* factCPS : int -&gt; (int -&gt; 'a) -&gt; 'a *)
(* REQUIRES: true *)
(* ENSURES: factCPS n k ~= k (n!) *)
fun factCPS 0 k = k 1
  | factCPS n k = factCPS (n-1) (fn res =&gt; k (n * res))
</code></pre>
<p>Here, <code>factCPS</code> takes in two arguments - one is the counter for the factorial
function (as normal), and the other is the <em>continuation</em>. In this case, the
continuation is a function from <code>int -&gt; 'a</code>. The idea here is that the
continuation should represent what work is <em>left to do</em>. It is left polymorphic,
however, in order to give the user control over what they want the function to
do. In order to compute the factorial of <code>n</code> directly, one could just evaluate
<code>factCPS n Fn.id</code>, however we grant more versatility to the user in that they
are not <em>just</em> constrained to computing the factorial. If one wanted a textual
representation of the factorial of <code>n</code>, they could evaluate <code>factCPS n Int.toString</code>, for instance. This way, we get additional versatility out of our
implementation.</p>
<p>We will now consider a trace of <code>factCPS 3 Int.toString</code> to fully understand the
mechanism by which it works.</p>
<figure class="aligncenter">
    <img src="concepts/../assets/cps.png" alt="CPS Trace" width="1500"/>
    <figcaption><b>Fig 1.</b> Code trace of the evaluation of `factCPS 3 Int.toString` </figcaption>
</figure>
<p>As we can see, this code trace does correctly result in <code>Int.toString 6</code>, which
is our desired result. Of particular interest to our analysis is the
<em>continuation</em> of the function, which seems to grow with every line through
<code>factCPS</code>'s recursion, until ultimately being reduced down step-wise until it
yields our final result. </p>
<p>The colors in the image denote the difference between the <em>current</em> value of <code>k</code>
and the new, <em>constructed</em> k. For instance, <code>k</code> is originally <code>Int.toString</code>
(which is the blue-colored text), however it is eventually wrapped in <code>(fn res =&gt; ... (3 * res))</code>, which is the RHS of the call to <code>factCPS 3 Int.toString</code>.
Thus, the &quot;inner&quot; <code>k</code> in the third line is in orange, to signify that it is in
fact the same as the entire continuation from the previous line (also in
orange), which is the &quot;previous&quot; <code>k</code>. Seen in this way, all that each recursive
call seems to be doing is appending a layer to the continuation, while the
inside remains the same.</p>
<p><strong>NOTE:</strong> The definition of <code>factCPS</code> says that the input to each lambda
expression should be named <code>res</code>. In order to make understanding clearer and
avoid namespace collisions, we have opted to name it <code>res</code>, <code>res2</code>, and <code>res3</code>,
on each recursive call to <code>factCPS</code>. Note that this renaming does not affect the
evaluation of <code>factCPS 3 Int.toString</code> and does keep it exactly equivalent to
how it is actually evaluated<a href="concepts/cps.html#footnote1"> <sup> [1] </sup> </a>.</p>
<p>So hopefully now we are convinced of <code>factCPS</code>'s correctness<a href="concepts/cps.html#footnote2"> <sup>[2]</sup> </a>. What might not be evident, however, is <em>why</em>. </p>
<p>Recall our previous metaphor with regards to writing down instructions. It is
hopefully not too difficult to see that this large lambda expression that we are
constructing is akin to writing down instructions - we specify the operations
that should occur when it is ultimately &quot;collapsed&quot; (by being given an input
value), but nothing actually occurs until then. It merely encodes that
information in the meantime. The next diagram will attempt to more specifically
show this relationship between the &quot;instructions&quot; and how it arises from the
definition of <code>factCPS</code>:</p>
<figure class="aligncenter">
    <img src="concepts/../assets/updown.png" alt="Instructions" width="1500"/>
    <figcaption><b>Fig 2.</b> Relationship between an arbitrary recursive call of `factCPS` and the "instructions" that it writes down. </figcaption>
</figure>
<p>The middle of this image is supposed to denote the &quot;instructions&quot; that you might
write if you were to codify the algorithm to determine the factorial of \( n \).
Note that these instructions are actually read from bottom to top - thus, we
start with 1 and then work out way up multiplying until we reach \( n \), which
presumably should give us the actual factorial. </p>
<p>Now consider if we were at some arbitrary point of execution of the expression
<code>factCPS n initK</code>, for some arbitrary <code>initK : int -&gt; 'a</code>. That is, suppose that 
<code>factCPS n initK</code> has reduced down to <code>factCPS i k'</code>, for some other <code>k</code> (which 
is the result of modifying the continuation throughout the recursive calls of 
<code>factCPS</code> until now. Then, we should see that the form of <code>k</code> should look something 
like <code>(fn res =&gt; (fn res2 =&gt; ... (fn resn =&gt; initK (n * resn)) ... ((i + 2) * res)) ((i + 1) * res))</code>. That is, it exactly captures the idea of the instructions in
orange - it covers the multiplication of all of the terms from \( i+1 \) to \( n \). </p>
<p>What is the action of the recursive call <em>at</em> <code>factCPS i k</code>? Well, clearly it
should reduce to <code>factCPS (i-1) (fn res =&gt; k (i * res))</code> - that is, it wraps <code>k</code>
in the lambda expression <code>(fn res =&gt; k (i * res))</code>, which is just the
&quot;instruction&quot; to multiply the result by <code>i</code>, which exactly corresponds to the
instruction in blue.</p>
<p>How do we compute the rest of the factorial function? Everything seems correct
so far, but that is all that we will have in our accumulation of <code>k</code>. The rest
of the instructions are exactly corresponding to the recursive call - to
<code>factCPS i</code> itself. <code>factCPS i</code>, as the recursive call, will continue to go and
compute the factorial all the way down to 0. Thus, even though we have not
written them down yet, we can use the &quot;recursive leap of faith&quot; to <em>assume</em> that
<code>factCPS i k</code> will behave properly, and write down the instructions for
multiplying <code>i-1</code> through <code>1</code> properly, which will result in the final, correct
result.</p>
<p><strong>NOTE:</strong> An equivalent, but also very <em>important</em> way to view CPS functions is
that recursive calls <em>pass their result</em> to their continuation. For instance, as
we have defined, <code>factCPS n k</code> should be extensionally equivalent to <code>k (fact n)</code>, or in other words, <code>factCPS n k</code> will be the same as passing the actual
factorial of <code>n</code> to <code>k</code>. This means that when we are writing our function, we
can make that assumption - <code>factCPS (n-1) (fn res =&gt; k (n * res))</code> should pass
the result of \( (n-1)! \) to <code>(fn res =&gt; k (n * res))</code>. This is equivalent to, in
our &quot;instructions&quot; analogy, saying that <code>factCPS i k</code> should faithfully execute
all the instructions of multiplying from <code>1</code> to <code>i</code> - that is, <code>factCPS i k</code>
should pass the result of \( i! \) to <code>k</code>.</p>
<p>So now, we can sort of inductively see how <code>factCPS</code> writes down the entire page of
instructions, which should mean that it is correct when we execute it. This is
not an inductive proof in itself, but this should give the intuition for <em>why</em>
it does work.</p>
<p>An additional way to think about CPS functions is that they behave similarly to
a <em>stack</em>. This is because, as we have seen, we are continuously wrapping lambda
expressions with other lambda expressions - we can only &quot;pop&quot; off a lambda
expression by evaluating it with an argument, or &quot;push&quot; on more instructions by
wrapping our continuation in more lambda expressions. We cannot access the ones
inside. As such, we could visualize the evaluation of <code>factCPS 3 k</code>
as the following diagram:</p>
<figure class="aligncenter">
    <img src="concepts/../assets/stack.png" alt="CPS Stack" width="1500"/>
    <figcaption><b>Fig 3.</b> A visualization of the "stack" of instructions created by evaluating `factCPS 3 k`. </figcaption>
</figure>
<p>We would build this stack up from the bottom by first putting our <code>k</code> on (as our
&quot;original&quot; <code>k</code>), then wrapping it in more lambda expressions as we go along the
recursive calls (so, for instance, the orange brick is added by <code>factCPS 3 k'</code>, and
the red brick is added by <code>factCPS 2 k''</code>, for their own respective continuations
<code>k'</code> and <code>k''</code>). Then, once we are at the end, our &quot;instruction stack&quot; looks
like the one currently pictured. At that point, we have nothing left to do but
execute the stack of instructions with an initial value of <code>1</code>, which will cause
the bricks to start being popped off one by one, and then ultimately result in the 
value of <code>6</code> being applied to <code>k</code>. </p>
<p>Another, equivalent way to view continuations is as <em>donuts</em>.</p>
<figure class="aligncenter">
    <img src="concepts/../assets/donut.png" alt="CPS Donut" width="1500"/>
    <figcaption><b>Fig 4.</b> An artist's rendition of the "CPS Donut" of instructions created by evaluating `factCPS 3 k` (colorized, 2020). </figcaption>
</figure>
<p>As you can see, we cannot access the inner layers of the CPS Donut without first
biting through the outer layers (corresponding to our evaluation of the outer
layers first). One can only imagine what it would taste like in real life.</p>
<p><strong>NOTE:</strong> It is not important to be able to draw these examples, or parrot them
verbatim. They are merely here to try and provide some intuition as to what is
happening with CPS. It is very important to be able to understand <em>why</em> it is
that CPS functions work, which may be rather daunting and hard-to-grasp at
first.</p>
<h3><a class="header" href="#footnotes-2" id="footnotes-2">Footnotes</a></h3>
<p><a id="footnote1"> [1]: In fact, it is
<a href="https://en.wikipedia.org/wiki/Lambda_calculus#Alpha_equivalence"><em>alpha equivalent!</em></a> </a></p>
<p><a id="footnote2"> [2]: Though perhaps we should not be, until we write a full inductive proof of correctness! </a></p>
<h2><a class="header" href="#continuation-passing-style-the-definition" id="continuation-passing-style-the-definition">Continuation Passing Style: The Definition</a></h2>
<p>We are now ready to attempt a definition of continuation passing style.</p>
<blockquote>
<p><strong>[Continuation]</strong> A <em>continuation</em> is a function that specifies what is
supposed to be done with the result of a computation.</p>
</blockquote>
<blockquote>
<p><strong>[Continuation Passing Style]</strong> A function is said to be written in
<em>continuation passing style</em> if it satisfies the following conditions:</p>
<ol>
<li>
<p>It takes in and uses continuation(s).</p>
</li>
<li>
<p>It calls functions with continuations (including itself) as tail calls.</p>
</li>
<li>
<p>It can only call its continuations in tail calls.</p>
</li>
</ol>
<p>The key characteristic of CPS functions is that they are generally written
with the goal of <em>passing their results to their continuations</em>. These
continuations specify what computations should occur next.</p>
</blockquote>
<p>First, take a moment to assure yourself that the implementation of <code>factCPS</code>
that we have so deeply studied <em>is</em>, in fact, in continuation passing style<a href="concepts/cps.html#footnote3">
<sup> [3] </sup></a>.</p>
<pre><code class="language-sml">fun factCPS 0 k = k 1
  | factCPS n k = factCPS (n-1) (fn res =&gt; k (n * res))
</code></pre>
<p>As we have seen, clearly <code>k</code> is <code>factCPS</code>'s continuation, and it does call it in
tail calls (as well as itself). This seems consistent with our definition. </p>
<p>An important corollary of this definition is that a CPS function <em>cannot case on
a recursive call to itself</em>. So, for instance, making a recursive call to a CPS
function to see if it succeeds, then taking some action based on that premise is
illegal. You may not fully understand what that means at the present, but we
will explore this idea more in the future.</p>
<p>A somewhat interesting note is that every direct-style (which is how we will
term the kinds of functions that we have written until now) function admits a
continuation passing style implementation. This means that continuation passing
style is nothing arcane, but it is merely a <em>different way of viewing
computation</em>. Functions written in continuation passing style can have
significant performance benefits when compared to their direct style
counterparts, so there are reasons to use continuation passing style other than
just for the sake of it. </p>
<h3><a class="header" href="#footnotes-3" id="footnotes-3">Footnotes</a></h3>
<p><a id="footnote3"> [3]: Otherwise, you should be quite concerned about the competency of the author, and you would probably be better off reading a different help site.</p>
<h2><a class="header" href="#continuation-passing-style-a-case-study-v20" id="continuation-passing-style-a-case-study-v20">Continuation Passing Style: A Case Study v2.0</a></h2>
<p>We will now explore an example of a CPS function that makes use of some concept
of limited <em>backtracking</em>, or <em>checkpointing</em>. Somewhat key to this example is
that it writes down not just <em>one</em> instruction at each recursive call, but
<em>multiple</em>.</p>
<pre><code class="language-sml">fun treeSumCPS Empty k = k 0
  | treeSumCPS (Node (L, x, R)) k = 
  treeSumCPS L (fn leftSum =&gt; treeSumCPS R (fn rightSum =&gt; k (leftSum + x + rightSum))
</code></pre>
<p>This function computes the sum of the elements in an int tree. The recursive
case has a slightly more intimidating-looking continuation, however we can view
it as simply a case of the continuation being wrapped <em>twice</em>.</p>
<p>Consider how we would normally want to approach this problem. In a typical
<code>treeSum</code>, we might compute both the left and right sums, and then simply add
the results to <code>x</code>. This suffices, and follows rather intuitively, but in CPS we
must make our control flow <em>explicit</em>. In this manner, we must be very specific
about <em>what</em> we should do and in which <em>order</em>. To that end, we fix a direction
to visit first (in this case, left, though it does not matter), and then compute
the sum of that direction, with the promise that we will eventually use the
result of the left side to compute the final result.</p>
<p>To visualize what is happening, consider the following tree.</p>
<figure class="aligncenter">
    <img src="concepts/../assets/cpsTree.png" alt="Tree to be summed"
    width="200" class="center"/>
    <figcaption><b>Fig 5.</b> A tree of ints to be summed, whose node contents are conveniently enumerated according to visit order. </figcaption>
</figure>
<p>We will run through a mock simulation of the evaluation of <code>treeSumCPS T k</code>,
where <code>T</code> is the tree pictured, and <code>k</code> is some arbitrary continuation. First,
note that we will take the convention that &quot;Tn&quot; for some number n will denote
the subtree rooted at the vertex n, and &quot;Sn&quot; will denote the sum of that
subtree.</p>
<p>Firstly, we know that from <code>treeSumCPS T k</code> we should obtain <code>treeSumCPS T2 (fn S2 =&gt; treeSumCPS T4 (fn S4 =&gt; k (S2 + 1 + S4))</code>.</p>
<figure class="aligncenter">
    <img src="concepts/../assets/phase1.png" alt="Phase 1"
    width="3000" class="center">
    <figcaption class="center"><b>Fig 6.</b> Phase 1 of evaluation of the tree T. </figcaption>
</figure>
<p>We can think of the individual calls to <code>treeSumCPS</code> on <code>T2</code> and <code>T4</code> as leaving
&quot;flags&quot; on each arm of the edges coming from vertex 1 - denoting which node that
we should visit next. Clearly, we visit <code>T2</code> first, so the red brick
corresponding to <code>T2</code> is on top.</p>
<p>Our next move is to pop it off first, which will cause our expression to now
have three bricks - two corresponding to the children of <code>T3</code>, and one
corresponding to <code>T4</code>. We can visualize the next phase as the following:</p>
<figure class="aligncenter">
    <img src="concepts/../assets/phase2.png" alt="Phase 2"
    width="3000" class="center">
    <figcaption class="center"><b>Fig 7.</b> Phase 2 of evaluation of the tree T. Note that two extra "bricks" have been added due to evaluation of treeSumCPS T2. </figcaption>
</figure>
<p>where the brick labelled <code>treeSumCPS E</code> corrresponds to the empty child of
<code>T2</code>. Note that we have retained the blue flag at <code>T4</code> and left its brick alone,
since for all intents and purposes we have not yet &quot;touched&quot; it - we have not
evaluated our stack to that point. Note that due to corresponding to the <code>Empty</code>
case, the purple brick will not add any new bricks, but merely defer to the next
brick on the stack - the orange brick. Thus, the next step looks like the
following:</p>
<figure class="aligncenter">
    <img src="concepts/../assets/phase3.png" alt="Phase 3"
    width="3000" class="center">
    <figcaption class="center"><b>Fig 8.</b> Phase 3 of evaluation of the tree T. Note that this follows from evaluating both of the top bricks from the previous step. </figcaption>
</figure>
<p>In this step, the green and light blue bricks again correspond to empty trees,
so they simply dissolve without generating more instructions. As such, we reduce
to the following diagram:</p>
<figure class="aligncenter">
    <img src="concepts/../assets/phase4.png" alt="Phase 4"
    width="3000" class="center">
    <figcaption class="center"><b>Fig 9.</b> Phase 4 of evaluation of the tree T. Note that, after finishing our evaluation of all of the bricks of the left side, we return to our long-neglected "checkpoint" on the right side of the tree.. </figcaption>
</figure>
<p>We see in this step that, as the figure caption says, we have returned to the
right hand side after finishing all evaluation on the left hand side of the
tree. Thus, our construction was correct - we placed the blue brick onto the
stack at the very beginning, then proceeded to forget about it until now. This
works in our favor, however, as we only return to it once we have finished with
everything on the left. One more step of evaluation yields:</p>
<figure class="aligncenter">
    <img src="concepts/../assets/phase5.png" alt="Phase 5"
    width="3000" class="center">
    <figcaption class="center"><b>Fig 10.</b> Phase 5 of evaluation of the tree T. </figcaption>
</figure>
<p>Thus, all we have left are empty bricks, so we are very close to termination.</p>
<p>This demonstration was far from a rigorous treatment, and also omitted any
mention of the actual value being passed into each continuation - this can be
inductively assumed to be the proper sum at any given brick. We invite the
reader to conduct any detailed analysis on their own, similarly to the treatment
of <code>factCPS</code>, in order to truly grasp how the different subtree sums are
computed and passed around.</p>
<p>The main point in this example, however, was to demonstrate how even a slightly
more complicated function can result in elegant, powerful control-flow behavior.
By simply wrapping our continuation twice, we ensured that we could set up a
&quot;checkpointing&quot; system, where we could set &quot;flags&quot; to jump back to once
finishing a certain computation. This is an important idea to cognize with
continuation passing style. </p>
<p>In the next example, we will explore how we can set up more complicated
arrangements of control flow through usage of two continuations.</p>
<h2><a class="header" href="#continuation-passing-style-a-case-study-in-success-and-failure" id="continuation-passing-style-a-case-study-in-success-and-failure">Continuation Passing Style: A Case Study in Success and Failure</a></h2>
<p>Duality seems to permeate computational problems. When trying to write programs,
we often come to cases where we need to make a choice between two extremes - on
or off, keep or don't, left or right, 1 or 0. With the capacity to make choices,
however, comes the possibility of making the <em>wrong</em> choice. In such a case, we
might want the ability to remember the choice we made, and take the other one,
or <em>backtrack</em>. </p>
<blockquote>
<p><strong>[Backtracking]</strong> Backtracking is a strategy employed by algorithms when
trying to find all the possible &quot;options&quot; or &quot;possibilities&quot;, so as to locate
the &quot;best&quot; solution, or alternatively just one feasible solution. Problems
that admit backtracking solutions include the N-queens puzzle, constraint
satisfaction problems, and Sudoku.</p>
</blockquote>
<p>At first, backtracking might seem like it is akin to what was done in the
previous example, with our idea of &quot;checkpointing&quot;, except that we never really
&quot;reset&quot; our state. When we set checkpoints to go back to in the <code>treeSumCPS</code>
example, we always did so while retaining the sum of the left side, so we never
lost information. In a backtracking problem, we may need to throw away
everything that we've done in the meantime and go to a different solution
entirely.</p>
<p>In this example, we will analyze a classic optimization problem, and how it
admits a CPS solution.</p>
<blockquote>
<p><strong>[Knapsack Problem - Decision Version]</strong> The <em>knapsack problem</em> is a resource
allocation problem which traditionally concerns a person with a knapsack that
can only contain a certain total weight of items. The person has to choose between a
collection of items (all of differing weight and value) so as to maximize the
amount of value collected, while being below the maximum weight limit of the knapsack.
Note that items can be taken more than once.</p>
<p>In this chapter, we will be concerned specifically with the <em>decision problem</em>
version of the knapsack problem, which, instead of asking for a maximizing
assignment, instead asks if there <em>exists</em> an assignment that can achieve a
certain threshold of value.</p>
</blockquote>
<p>We will now write a continuation passing style function that solves the
knapsack problem.</p>
<pre><code class="language-sml">type weight = int
type value = int

(* knapsackCPS : 
 *            (value * weight) list -&gt; 
 *            value -&gt; 
 *            weight -&gt; 
 *            ((value * weight) list -&gt; 'a) -&gt; 
 *            (unit -&gt; 'a) -&gt; 
 *            'a 
 * REQUIRES: The weights and values of the elements in L are strictly positive.
 * ENSURES: knapsackCPS L minVal maxWeight sc fc ~= sc L' for some L' that only
 * contains elements of L, such that the total value of L' &gt;= minVal and the 
 * total weight of L' &lt;= maxWeight, if such an L' exists. If no such L' exists, 
 * then it should be equivalent to fc ().
 *)

fun knapsackCPS 
  (L : (value * weight) list) 
  (minVal : value) 
  (maxWeight : weight) 
  (sc : (value * weight) list -&gt; 'a) 
  (fc : unit -&gt; 'a)
  : 'a =
  case L of
    [] =&gt; if minVal &lt;= 0 andalso maxWeight &gt;= 0 then sc [] 
                                                else k ()
  | (v, w)::xs =&gt; if maxWeight &lt; 0 then k ()
                                   else
    knapsackCPS ((v, w)::xs) (minVal - v) (maxWeight - w) 
    (fn L' =&gt; sc ((v, w)::L')) (fn () =&gt; knapsackCPS xs minVal maxWeight sc fc)
</code></pre>
<p>We see that <code>knapsackCPS</code> takes in a list of items, each represented as 
a <code>value * weight</code> tuple, where <code>value</code> and <code>weight</code> are both really just 
aliases for <code>int</code>. It also takes in a minimum threshold for the knapsack's 
value, <code>minVal</code>, and a maximum weight of items to be taken <code>maxWeight</code>. Of 
particular interest, however, are the parameters <code>sc</code> and <code>fc</code> - denoting 
what we call the <em>success</em> and <em>failure</em> continuations. The goal of our 
function is to ultimately find a list <code>L'</code> that contains elements that are also 
in <code>L</code> (with duplicates allowed). This corresponds to choosing how many of each 
item in the allowed collection to pick.</p>
<p>If such a list exists, then we should return <code>sc L'</code>. Otherwise, if there is no
such list, we should return <code>fc ()</code>. </p>
<p>Rather immediately, this should seem as a kind of different problem. There isn't
really a better algorithm than brute forcing possibilities, but if we try a
possibility and it turns out to be wrong, we want to have the option to be able
to <em>backtrack</em> and try something else entirely. We will demonstrate how this is
realized in the algorithm in the next part.</p>
<pre><code class="language-sml">case L of
    [] =&gt; if minVal &lt;= 0 andalso maxWeight &gt;= 0 then sc [] 
                                                else k ()
</code></pre>
<p>For the base case, however, we know that if we are given no items whatsoever,
then we cannot place anything in our knapsack. Thus, we have no choice but to
have a value and weight of 0. As such, if we know that our minimum value is at
most 0 and our maximum weight is at least 0, then a valid list value for <code>L'</code> is
just the empty list, so we can call our success continuation in <code>sc []</code>. Otherwise, 
we must call the failure continuation, as the problem is not solvable.</p>
<p>Note that, since we plan to write this function recursively, if we were given an
initial list that was non-empty, we may eventually recurse down to the empty
case. It may then seem like a concern that we are calling <code>sc []</code>, as we might
actually call <code>sc</code> on a list that contains elements. Note that this is not a
concern - by the structure of CPS functions, if we were to recurse down to the
base case, our &quot;promise&quot; is that the success continuation <code>sc</code> that we enter the
base case with is not the &quot;original&quot; <code>sc</code> that we were passed - by this point,
it should have accumulated a great deal of &quot;information&quot; and thus become more
advanced than simply returning <code>sc []</code>, for the original <code>sc</code>. For the base
case, it is sufficient to simply solve it from the perspective of having been
originally given <code>[]</code>.</p>
<p>In the recursive case, we now have to think about how we might solve the
knapsack problem given that we have a non-empty collection of items to take.
Right off the bat, we can say that if our <code>maxWeight &lt; 0</code>, then this problem is
unsolvable, since we cannot possibly have a negative total weight (our weights
in this problem are strictly positive), so in that case we would simply call our
failure continuation.</p>
<p>Otherwise, however, we now need to actually think about what to do. Oftentimes,
it is very helpful reduce the problem to making a <em>binary choice</em>, and then
simply explore the consequences of doing so from there. In this case, we can
imagine our choice to be whether to put the first element of the list into the
knapsack, or to not. </p>
<pre><code class="language-sml">| (v, w)::xs =&gt; if maxWeight &lt; 0 then k ()
                                   else
    knapsackCPS ((v, w)::xs) (minVal - v) (maxWeight - w) 
    (fn L' =&gt; sc ((v, w)::L')) (fn () =&gt; knapsackCPS xs minVal maxWeight sc fc)
</code></pre>
<p>What does our recursive call for putting the first element <code>(v, w)</code> into the
knapsack look like? It takes the form of <code>knapsackCPS ((v, w)::xs) (minVal - v)  (maxWeight -  w) sc' fc'</code>, for some <code>sc'</code> and <code>fc'</code> that we will determine later. We 
keep the list the same, to account for the fact that we can have duplicates - in the 
next step, we want to reconsider whether we want to put <code>(v, w)</code> on again. If we
commit to putting <code>(v, w)</code> in the knapsack, however, we need to somehow encode
the fact that our value has gone up by <code>v</code>, and our knapsack's weight has gone
up by <code>w</code>. This is achieved by setting the new minimum value to be <code>minVal - v</code>,
and the new max weight to be <code>maxWeight - w</code> - we simply lower our thresholds,
which is functionally the same.</p>
<p>What should our continuations be? Remember that by the recursive leap of faith,
we can assume a kind of &quot;promise&quot; of this recursive call - that is, we can
assume that <code>knapsackCPS ((v, w)::xs) (minVal - v) (maxWeight - w) sc' fc'</code>
obeys the same ENSURES clause as was written above, for its own <code>sc'</code> and <code>fc'</code>.
We now should define what to do in the case that either is called.</p>
<p>We are, at this point, not actually at the stage where we know if <code>sc'</code> or <code>fc'</code>
is going to be called, or on what, if at all. The power in CPS comes from the
fact that this <em>does not matter</em>, and we can write our algorithm despite
that. Earlier, we discussed the concept of continuations as <em>contingency plans</em>.
In this function, we are going to be using that strategy to full effect.</p>
<p>Think of <code>sc'</code> and <code>fc'</code> as contingency plans for the success and failure case,
respectively. <em>If</em> we were to succeed on this recursive call, what should we do?
If we were to fail, what should we do? Even though we have no idea what the
input to the continuation is, the fact that it is a function allows us (inside
the scope of the body of <code>sc'</code>) to <em>assume we have access to it</em>. </p>
<p>As such, the first thing we may write for <code>sc'</code> is <code>fn L' =&gt; ...</code>. Now, we must 
fill in the ellipses. If <code>sc'</code> is called, we know that it must be called with an 
appropriate <code>L'</code> that satisfies the ENSURES conditions. Recall that this recursive call
emerged in the first place from our <em>choice</em> - to place <code>(v, w)</code> inside of the
knapsack. Thus, if the call to <code>knapsackCPS</code> succeeds, we know that placing <code>(v, w)</code> inside the knapsack must be feasible, by extension. So then we know it makes
sense to write <code>fn L' =&gt; sc ((v, w)::L')</code> for <code>sc'</code>, which intuitively means
&quot;take the answer (knapsack) to the recursive call and then put <code>(v, w)</code> in it,
then call success on it&quot;. Thus, we have written down a <em>contingency plan</em> for
what we should do <em>if</em>, at some point in the future, our success continuation is
called.</p>
<p>What about <code>fc'</code>? What should we do if we fail? Well, if our recursive call to
<code>knapsackCPS</code> does not succeed, that must mean that our choice to place <code>(v, w)</code>
inside of the knapsack was wrong. In that case, we want to make the other choice - 
to not put <code>(v, w)</code> inside the knapsack. Thus, we write <code>fn () =&gt; knapsackCPS xs minVal maxWeight sc fc</code>, which has the exact same parameters as what we were
initially passed, except we have gotten rid of <code>(v, w)</code> (since we know to put it
in the knapsack is a mistake). Our <code>sc</code> and <code>fc</code> remain the same, since on a
sucess or fail to this call, we just do whatever we would normally do on a
success or fail.</p>
<p>This, in only a few lines (and generous whitespace), we have written an
algorithm for a backtracking knapsack problem solver. While it looks
intimidating at first, the overall algorithm reduces down to only a few simple
steps, which is written in an elegant and explicit manner due to continuation
passing style.</p>
<h2><a class="header" href="#conclusions-2" id="conclusions-2">Conclusions</a></h2>
<p>In this section, we explored the idea of continuation passing style, which lets
us phrase the control flow of our functions in a more explicit manner, granting
us more versatility in our implementation. We saw how CPS functions can be
viewed as simply a more advanced form of accumulation, as well as how having
multiple continuations (corresponding to success and failure cases) allows us to
explore expansive trees of binary choices to find solutions.</p>
<h1><a class="header" href="#exceptions" id="exceptions">Exceptions</a></h1>
<p>So far, we have seen how we can manipulate the constructs of SML to create
unique control flow behavior in the form of continuation passing style. In this
section, we will discuss <em>exceptions</em>, which are themselves a builtin feature of
the language. With exceptions, we can cover cases where continuing to evaluate an
exprerssion does not make sense or is ill-defined at run-time.</p>
<h2><a class="header" href="#built-in-exceptions" id="built-in-exceptions">Built-In Exceptions</a></h2>
<p>We have seen how SML interprets computation as evaluation, and how we can reduce
our entire notion of program execution to application of simple reduction rules.
Sometimes, however, we run into cases where attempting to apply some rule
results in an error, or in some output that we cannot actually
express. In such cases, it is necessary to actually <em>halt</em> evaluation with some
manner of effect - this is the behavior that exceptions will introduce.</p>
<p>While we would like to be able to push as many of these errors as possible to compile 
time, it is not always the case that this is possible - this is usually when
dealing with cases where computation is made infeasible by the <em>values</em>
that are bound to identifiers, which cannot be determined <em>a priori</em> at compile
time. As such, we have no way of telling beforehand if such errors will occur -
forcing us to define some notion of a <em>run-time error</em>.</p>
<p>You have likely already encountered exceptions - the canonical example is of <code>1 div 0</code>, which, when entered in the REPL, will result in an <code>uncaught exception Div</code>. This is because we cannot sensically evaluate <code>1 div 0</code> to some value -
what integer could we possibly return? The other option, then, is to simply
quit, and not even try to evaluate further. This is why division by zero results
in an exception.</p>
<p>Another example is of the declaration <code>val x::xs = []</code>. This signifies an
attempt at pattern matching, where we attempt to pattern match <code>x::xs</code> to <code>[]</code>.
Plainly, however, we cannot possibly carry this out - what values could we bind
to <code>x</code> and <code>xs</code> to make this valid? Thus, we will also need to have some
exception for an incorrect binding - which is appropriately named as the <code>Bind</code>
exception.</p>
<p>Finally, in general we are interested in writing functions that are
<em>exhaustive</em>, in that they are defined on all values of their input type. Even
if a function is only <em>meant</em> to be called on values within a certain domain, it
is often a good idea to be safe and cover all of the cases anyways. We call such
a function that is not defined on certain inputs <em>nonexhaustive</em>, and defining
them will generally result in a non-exhaustive match warning, though it will
still be permitted.</p>
<p>Consider the function <code>fn true =&gt; 1</code>, which is plainly nonexhaustive, not
covering the <code>false</code> case. Nonetheless, it is a function of type <code>bool -&gt; int</code>
that can be bound to an identifier. How, then, should we handle the case of
attempting to evaluate <code>(fn true =&gt; 1) false</code>? This is a well-typed expression,
causing it to fly under the radar of our compile-time tests. At run-time, then,
we cannot evaluate this expression through function application - the function
does not specify what it should return in this case! As such, we will simply
raise a <code>Match</code> exception, signifying that the function's input was not able to
match to any particular clause of the function. Note how this differs from
<code>Bind</code>, which occurs as a result of attempting to produce a binding, not when
attempting to apply a function.</p>
<h2><a class="header" href="#defining-exceptions-basic" id="defining-exceptions-basic">Defining Exceptions: Basic</a></h2>
<p>We have now seen the built-in exceptions that are automatically raised for
certain prescribed use cases. Oftentimes, however, we are interested in our own
specified use cases, meaning that we likely do not want to use the exceptions
<code>Div</code>, <code>Match</code>, and <code>Bind</code>, which may be unrelated. In this case, we want to
define our own exceptions.</p>
<p>The syntax for defining exceptions is as follows:</p>
<pre><code class="language-sml">exception Error
</code></pre>
<p>This introduces the constructor named Error, which corresponds to the
identically named exception Error. Exception constructors are <em>first class</em>,
meaning that they are themselves values. The type of exception constructors is
<code>exn</code>, so this line really introduces the value <code>Error : exn</code>. The type <code>exn</code>
stands for &quot;exception name&quot;, but it is also useful to think of it as standing
for &quot;extensible&quot;, since the type <code>exn</code> is <em>extensible</em>. This means that we
can <em>extend</em> the values that populate <code>exn</code> with new constructors, like we did 
with <code>Error</code>.</p>
<p>The value <code>Error</code> is not, by itself, an exception, however we can use it to
raise exceptions with the <code>raise</code> keyword. We can think of the <code>raise</code> keyword
as being &quot;like&quot; a function of type <code>exn -&gt; 'a</code>, in that it &quot;takes in&quot; a value of
type <code>exn</code> and has type <code>'a</code>. It is important to remember that <code>raise</code> is <em>not</em>
a function really, though - it merely has similar behavior when used to raise
exceptions, but it is not first class.</p>
<p>The polymorphic &quot;return type&quot; of the <code>raise</code> keyword is so that raising
exceptions can be compatible with our type system. Suppose we want to write a
factorial function that, instead of looping forever on negative inputs, raises
an exception.</p>
<pre><code class="language-sml">exception Negative

fun fact' 0 = 1
  | fact' n = 
      if n &lt; 0 then raise Negative
               else n * fact' (n-1)
</code></pre>
<p>This code fragment should carry out our desired behavior. Consider the type of
<code>raise Negative</code> - we would like to raise an exception, but we know that the
expressions in both branches of an if then else expression must be the same
type. In the positive case, this has type <code>int</code>, corresponding to just
calculating the actual factorial. Therefore the negative case must also be
<code>int</code>, though we also want to raise an exception. To be compatible with this, 
<code>raise Negative</code> must have type <code>int</code>.</p>
<p>We would not like <code>raise Negative</code> to have type <code>int</code> in <em>general</em>, however -
this depends on our use case! We want raising exceptions to be able to just
<em>work</em>, type-wise, since we know that it never returns a well-defined value anyways. 
As such, we define raising exceptions to have a <em>polymorphic</em> return type, so that
it fits within our type system correctly, no matter the use case. This is also
the reason why we can write <code>raise Fail &quot;Unimplemented&quot;</code> as the output of
not-yet defined functions and still pass typechecking, no matter how complicated
the function.</p>
<h2><a class="header" href="#exceptional-control-flow" id="exceptional-control-flow">Exceptional Control Flow</a></h2>
<p>At this point, we have seen how exceptions let us implement a very limited form
of &quot;control flow&quot;, in that we can stop the flow of control entirely - upon
encountering a raised exception, computation ceases. This is rather rudimentary
in terms of expressiveness - we can only create programs that forcibly
terminate! In this section, however, we will explore the usage of <code>handle</code>, a
keyword that allows us to have more sophisticated behavior with respect to
programs deal with raised exceptions.</p>
<blockquote>
<p><strong>[handle]</strong> For expressions <code>e : t</code>, <code>e1 : t</code> ... <code>en : t</code>, and different values 
<code>Exn1 : exn</code> ... <code>ExnN : exn</code>, if the expression <code>e</code> raises the exception
<code>ExnI</code>, then the expression </p>
<pre><code>e handle Exn2 =&gt; e1
       | Exn2 =&gt; e3
       ...
       | ExnN =&gt; en
</code></pre>
<p>reduces to <code>eI</code>.</p>
<p>In other words, the <code>handle</code> keyword lets us case on the exception raised by
an expression.</p>
</blockquote>
<p>It is important to note that all the expressions <code>e</code>, <code>e1</code>, ... <code>en</code> have to be
of the same type. Consider what would happen if they were not:</p>
<pre><code class="language-sml">e handle Div =&gt; &quot;Oh no!&quot;
</code></pre>
<p>Let <code>e</code> be an expression of type <code>int</code>. Suppose that, in this case, <code>e</code> raises <code>Div</code>, 
so ostensibly this expression should reduce to <code>&quot;Oh no!&quot;</code>. However, what would happen 
if <code>Div</code> was not raised? Then, we would have <code>e</code>, which is of type <code>int</code>.</p>
<p>We've violated type safety here. We cannot &quot;sometimes&quot; have an expression be one
type and another time have it be another. We must have <em>static type guarantees</em>.
As such, all the arms of a <code>handle</code> must agree, and additionally they must agree
with the type of the expression being handled.</p>
<p>We say that an exception that is raised can either propagate up to the <em>top
level</em> (in which case the program or expression simply results in an uncaught
exception), or to the <em>nearest handler</em>. To clarify the meaning of &quot;nearest&quot;,
take the evaluation of the expression <code>(1 + (1 div 0)) * 3 handle Div =&gt; 5</code>, for
example. We see that <code>1 div 0</code> raises the exception <code>Div</code>, so the inner
expression is extensionally equivalent to <code>(1 + raise Div) * 3</code>. Then, applying
this logic one more time, <code>1 + raise Div</code> clearly should also raise <code>Div</code>, so we
get that it is extensionally equivalent to <code>raise Div * 3</code>, which is then
extensionally equivalent to <code>raise Div</code>. What we see is that this raised
exception &quot;propagates up&quot; as it subsumes more and more expressions, until
eventually it reaches a handler.</p>
<p>While we now see how we can handle different kinds of exceptions, we might want
to make a more educated choice about what our next action should be. It might be
the case that we raise an exception in some failed branch of the program, but we
want to have more information about exactly what happened, or what the program
was doing at the time. We will now discuss <em>information-carrying exceptions</em>,
which are nothing other than an extension of our declarations of exceptions to
being more akin to how we declare datatypes.</p>
<p>In a similar vein to how we can declare <code>datatype Foo = Bar of int</code> to denote
that a value of type <code>Foo</code> is the constructor <code>Bar</code> wrapping a value of type
<code>int</code>, we can declare values of type <code>exn</code> to also be constructors wrapping
values. This takes the form:</p>
<pre><code class="language-sml">exception Crash of int
</code></pre>
<p>which denotes that <code>Crash 1</code> and <code>Crash 5</code>, among others, are values of type
<code>exn</code>, and can thus be <code>raise</code>d. Note that <code>Crash</code> thus has type <code>int -&gt; exn</code>.</p>
<p>Concretely, we can &quot;pattern match&quot; on the data contained by the exception
handler by doing something like the following:</p>
<pre><code class="language-sml">exception Return of int

fun factException 0 = raise Return 1
  | factException n = factException (n - 1) handle (Return res) =&gt; raise Return
  (n - 1)
</code></pre>
<p><strong>NOTE:</strong> It is not clear why anyone would want to define <code>fact</code> this way.</p>
<p>This example makes use of an exception, <code>Return : int -&gt; exn</code>, which wraps the
return value of <code>fact</code>. <code>fact</code>, at each step, simply raises an exception
containing its return value, which (in a future recursive call) is handled, the
value unwrapped (bound to <code>res</code>), then multiplied by the current value of <code>n</code> to
generate the next value, which is simply raised again. This is very similar to a
<code>case</code> expression - we simply pattern match on the raised exception's constructor 
using the handler (you can pattern match on exception constructors with <code>case</code> as
well, though not <em>raised</em> exceptions). Thus, the behavior of <code>factException n</code>
is to be extensionally equivalent to <code>raise Return (fact n)</code>.</p>
<p>For an abstract idea of a potential use case, consider some recursive function 
<code>f</code> that carries out some sequence of calculations, with a potential for error.
We might be interested in how many recursive calls such a function makes when it
ultimately fails - however, if we were to return the number of recursive calls,
we would constrain the return type to be <code>int</code>, or barring that, some datatype
that could be either a valid result (say, <code>Valid res</code>) or a signal for failure,
with a line number (say, <code>Fail line</code>). We might desire that on a fail, execution
actually stops, however. We could then simply raise the exception <code>Crash line</code>,
which, as a raised exception, has a polymorphic type. As such, exceptions allow
us to propagate back information <em>without altering types</em>, which can be
convenient for our purposes.</p>
<p>For a concrete example of using such exceptions, see the next section.</p>
<h2><a class="header" href="#exception-handling-style" id="exception-handling-style">Exception Handling Style</a></h2>
<p>In the previous section, we discussed how continuation passing style could be
used to devise complicated control flow schemas, in some instances being based
around the idea of a <em>success</em> and <em>failure</em> continuation, which could both
potentially execute disjoint sets of instructions. With continuations, we can
relate them to a common other construct in programming languages, that being a
<em>goto</em>. With a goto, we abandon whatever we are currently in the process of
doing in favor of something else. In this, we can see that continuations and
exceptions share similar characteristics, of being able to just &quot;stop&quot; execution
in favor of some other route.</p>
<p>Consider the knapsack example from the previous section. We will now implement a
solution to the knapsack problem using exception handling style.</p>
<pre><code class="language-sml">exception Failure

type weight = int
type value = int

(* knapsackEHS : 
 *            (value * weight) list -&gt; 
 *            value -&gt; 
 *            weight -&gt; 
 *            ((value * weight) list -&gt; 'a) -&gt; 
 *            'a 
 * REQUIRES: The weights and values of the elements in L are strictly positive.
 * ENSURES: knapsackEHS L minVal maxWeight sc fc ~= sc L' for some L' that only
 * contains elements of L, such that the total value of L' &gt;= minVal and the 
 * total weight of L' &lt;= maxWeight, if such an L' exists. If no such L' exists, 
 * then it should be equivalent to raise Failure.
 *)

fun knapsackEHS 
  (L : (value * weight) list) 
  (minVal : value) 
  (maxWeight : weight) 
  (sc : (value * weight) list -&gt; 'a) 
  : 'a =
  case L of
    [] =&gt; if minVal &lt;= 0 andalso maxWeight &gt;= 0 then sc [] 
                                                else raise Failure
  | (v, w)::xs =&gt; if maxWeight &lt; 0 then raise Failure
                                   else
    knapsackEHS ((v, w)::xs) (minVal - v) (maxWeight - w)  (fn L' =&gt; sc ((v, w)::L')) 
    handle Failure =&gt; knapsackEHS xs minVal maxWeight sc
</code></pre>
<p>It should be apparent that this function shares very close similarities to
<code>knapsackCPS</code>, with the exception<a href="concepts/exn.html#footnote1"> <sup> [1] </sup> </a> of
omitting the failure continuation for raising the <code>Failure</code> exception. In fact,
we can claim that <code>knapsackCPS L minVal maxWeight sc fc ~= knapsackEHS L minVal maxWeight sc handle Failure =&gt; fc ()</code>, for all relevant values. Take a moment to
assure yourself that this is the case. The code does not look very different,
with the largest change being the recursive case, where the failure continuation
has instead been offloaded to a handler.</p>
<p>Recall that we can think of the recursive call in the knapsack problem as a
&quot;choice&quot; to &quot;keep&quot; or &quot;not keep&quot; the item at the head of the list. We said
previously that, arbitrarily, we could commit to the choice of &quot;keep&quot;, with a
provision in the failure continuation to instead &quot;not keep&quot;, should that failure
continuation ever be executed. When evaluating the expression <code>knapsackEHS ((v, w)::xs) (minVal - v) (maxWeight - w) (fn L' =&gt; sc ((v, w)::L'))</code>
<a href="concepts/exn.html#footnote2"> <sup> [2] </sup> </a>, we know that one of two things can
happen - it can either <em>succeed</em> or <em>fail</em>. Now, however, our definition of
failure is different - instead of calling its failure continuation, an instance
of <code>knapsackEHS</code> which fails should instead raise <code>Failure</code>. Thus, it is exactly
the right thing to do to do what we would ordinarily do upon a failure, should
our call to <code>knapsackEHS</code> raise <code>Failure</code>.</p>
<p>Note, however, that in this implementation we put a slight amount more burden on
the user, since the ill-defined behavior of this function now results in a
raised <code>Failure</code>, instead of just invoking <code>fc ()</code>, for some pre-defined <code>fc</code>
that we input. This offers us the same advantages, however, since the return
types of <code>sc</code> and <code>fc</code> in <code>knapsackCPS</code> must be the same. As such, if we want
<code>knapsackCPS</code> to return some indicative value (without using an option type), we 
might not have an appropriate return value for the failure case. Thus,
<code>knapsackEHS</code> might have the behavior we're looking for, since the type of
<code>raise Failure</code> allows us to &quot;unconstrain&quot; the type of our success. In the
general case, however, we will not make heavy usage of exception handling style,
in favor of continuation passing style, which can be cleaner.</p>
<p>This is not the most committed that we could have made <code>knapsackEHS</code>, when
converting to exception handling style - we could have also represented <em>success
continuations</em> with a raised exception, an <code>exception Success of (int * int) list</code>. We will not cover such an implementation in this chapter, but we invite
the reader to try it out.</p>
<h3><a class="header" href="#footnotes-4" id="footnotes-4">Footnotes</a></h3>
<p><a id="footnote1"> [1]: We're funny.
<a id="footnote2"> [2]: Say that five times fast.</p>
<h2><a class="header" href="#conclusions-3" id="conclusions-3">Conclusions</a></h2>
<p>In this chapter, we explored <em>exceptions</em>, which allow us to have quick
transfers of control flow, albeit in a less &quot;controlled&quot; fashion than ways that
we have seen in the past. The success of so-called <em>exception handling style</em> is
heavily contingent on intelligent placement and consideration of <em>handlers</em>,
which decide where control is transferred to. We also have seen that we have a
way of passing information back <em>through</em> the raised exception, which allows us
to have a more powerful manner of communication than just an indicator of
failure. Exceptions ultimately allow us a robust and type-safe way to deal with 
run-time errors in our programs.</p>
<h1><a class="header" href="#modules" id="modules">Modules</a></h1>
<h1><a class="header" href="#signatures-and-ascription" id="signatures-and-ascription">Signatures and Ascription</a></h1>
<p>As discussed in the previous section, we sometimes will find ourselves working
on large projects, ones that have many different subtasks and subroutines. Other
times, we are implementing something that other programmers might want to use,
in which case we need to clearly and cleanly be able to convey what behaviors
our implementation supports. In such cases, we might be interested in
maintaining a <em>signature</em>, or <em>interface</em>, through which users have access to our implementation. </p>
<h1><a class="header" href="#motivation-3" id="motivation-3">Motivation</a></h1>
<p>Consider the computer. It is a complicated, convoluted work of machinery and
circuitry - at its most fundamental level being comprised of logic gates and
incredible networks of interacting parts. Although an action as simple as
opening up a notepad seems very intuitive to the user, under the hood it is
anything but. The key, however, is that the user of a computer need not
understand the underlying hardware and circuitry - indeed, they need not even
know what circuitry is! The user of the computer is restricted to an
<em>interface</em>, under which they can only interact with the computer with
particular, predefined ways. For the computer, this often takes the form of the
keyboard and mouse - beyond this, the user does not have the ability to reach
into the computer and manually flip the bits.</p>
<h2><a class="header" href="#signatures-and-structures" id="signatures-and-structures">Signatures and Structures</a></h2>
<p>In SML, this interface takes the form of a <em>signature</em>. A signature packages
types, values, and exceptions, among other things - though it does not have to
specify them. An interface, most of all, specifies what a particular module
should <em>do</em> - at the high level, how it should behave. For an example of this, 
let us consider the interface for a </p>
<h2><a class="header" href="#transparent-and-opaque-ascription" id="transparent-and-opaque-ascription">Transparent and Opaque Ascription</a></h2>
<h2><a class="header" href="#" id=""></a></h2>
<h1><a class="header" href="#applications" id="applications">Applications</a></h1>
<h1><a class="header" href="#cost-graphs" id="cost-graphs">Cost Graphs</a></h1>
<h1><a class="header" href="#examples" id="examples">Examples</a></h1>
<h1><a class="header" href="#sml-basics-examples" id="sml-basics-examples">SML Basics Examples</a></h1>
<h2><a class="header" href="#types-1" id="types-1">Types</a></h2>
<p>For each of the following declarations, state the type and value of <code>x</code>.</p>
<pre><code class="language-sml">val x = 1 &gt; 5
</code></pre>
<p>Type: <code>bool</code></p>
<p>Value: <code>false</code></p>
<pre><code class="language-sml">val x = 15 div 0
</code></pre>
<p>Type: <code>int</code></p>
<p>Value: Does not reduce to a value because it raises an exception</p>
<pre><code class="language-sml">val x = 15.0 div 0.0
</code></pre>
<p>Type: not well-typed (<code>div</code> is a function of type <code>int * int -&gt; int</code>)</p>
<p>Value: No value, since it is not well-typed</p>
<pre><code class="language-sml">val x = fn (n : int) =&gt; Int.toString n
</code></pre>
<p>Type: <code>int -&gt; string</code></p>
<p>Value: <code>fn n =&gt; Int.toString n</code></p>
<pre><code class="language-sml">val x = fn n =&gt; (&quot;1&quot; ^ &quot;5&quot;) ^ (Int.toString n)
</code></pre>
<p>Type: <code>int -&gt; string</code></p>
<p>Value: <code>fn (n : int) =&gt; (&quot;1&quot; ^ &quot;5&quot;) ^ (Int.toString n)</code></p>
<h2><a class="header" href="#scope" id="scope">Scope</a></h2>
<h3><a class="header" href="#example-0" id="example-0">Example 0</a></h3>
<pre><code class="language-sml">let
  val y : int = 2
in
  fn (x : int) =&gt; z*z
end
</code></pre>
<p>What is the value of the let-in-end expression?</p>
<p>Value: No value, because <code>z</code> is not in scope (will cause an error).</p>
<h3><a class="header" href="#example-1" id="example-1">Example 1</a></h3>
<pre><code class="language-sml">val y = 0
val z = 
    (let
      val x : int = 1
      fun f (x : int) = x
      val y : int = x + 1
    in
      fn (a : string) =&gt; x*2
    end) &quot;150&quot;
val a = y
</code></pre>
<p>What is the value of <code>y</code> before the let-in-end expression?</p>
<p>y = 0</p>
<p>What is the value of <code>y</code> within the let-in-end expression?</p>
<p>y = 2</p>
<p>What is the value of <code>a</code>?</p>
<p>a = 0</p>
<p>What is the value of <code>z</code>?</p>
<p>z = 2</p>
<h3><a class="header" href="#example-2" id="example-2">Example 2</a></h3>
<pre><code class="language-sml">val x : int = 1 
fun f (x : int) = x + 1
val y : int = 2
val z : int = f y
val a : int = x
</code></pre>
<p>What are the values of <code>x</code>, <code>y</code>, <code>z</code>, and <code>a</code>?</p>
<p>x = 1</p>
<p>y = 2</p>
<p>z = 3</p>
<p>a = 1</p>
<h3><a class="header" href="#example-3" id="example-3">Example 3</a></h3>
<pre><code class="language-sml">val x = 1
val y = 2
fun f (x, y) = 
    case x of 
      0 =&gt; 0
    | y =&gt; y
val a = f (y, x)
val b = f (x, y)
</code></pre>
<p>What are the values of <code>a</code> and <code>b</code>?</p>
<p>a = 2</p>
<p>b = 1</p>
<h1><a class="header" href="#recursion--induction" id="recursion--induction">Recursion &amp; Induction</a></h1>
<h1><a class="header" href="#about" id="about">About</a></h1>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
        
        

    </body>
</html>
